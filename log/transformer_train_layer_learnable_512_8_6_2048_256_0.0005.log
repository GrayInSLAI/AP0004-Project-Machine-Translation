
=== Output Directory: ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005 ===
Config: RMSNorm, Sinusoidal, Layers=6, Dropout=0.3
Loading Data...
Tokenizer Loaded. PAD ID: 1, SOS ID: 0, EOS ID: 2
Loading and Pre-tokenizing data from ./data/train_100k.jsonl...
Tokenizing: 0it [00:00, ?it/s]Tokenizing: 56988it [00:10, 5698.55it/s]Tokenizing: 100000it [00:18, 5414.96it/s]
Data Loaded. Kept: 100000, Filtered: 0 (Too long > 128)
Tokenizer Loaded. PAD ID: 1, SOS ID: 0, EOS ID: 2
Loading and Pre-tokenizing data from ./data/valid.jsonl...
Tokenizing: 0it [00:00, ?it/s]Tokenizing: 500it [00:00, 4770.41it/s]
Data Loaded. Kept: 500, Filtered: 0 (Too long > 128)
Tokenizer Loaded. PAD ID: 1, SOS ID: 0, EOS ID: 2
Loading and Pre-tokenizing data from ./data/test.jsonl...
Tokenizing: 0it [00:00, ?it/s]Tokenizing: 200it [00:00, 3775.10it/s]
Data Loaded. Kept: 200, Filtered: 0 (Too long > 128)
Model Initialized: LAYER Norm, LEARNABLE Pos Enc.
Starting Training...
Training:   0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=9.0535, lr=0.000000]Training:   0%|          | 0/391 [00:06<?, ?it/s, loss=8.4372, lr=0.000009]Training:  22%|██▏       | 85/391 [00:10<00:36,  8.42it/s, loss=8.4372, lr=0.000009]Training:  22%|██▏       | 85/391 [00:11<00:36,  8.42it/s, loss=8.0904, lr=0.000018]Training:  22%|██▏       | 85/391 [00:17<00:36,  8.42it/s, loss=7.6359, lr=0.000026]Training:  45%|████▍     | 175/391 [00:20<00:24,  8.75it/s, loss=7.6359, lr=0.000026]Training:  45%|████▍     | 175/391 [00:23<00:24,  8.75it/s, loss=7.2482, lr=0.000035]Training:  45%|████▍     | 175/391 [00:28<00:24,  8.75it/s, loss=6.9923, lr=0.000044]Training:  68%|██████▊   | 265/391 [00:30<00:14,  8.84it/s, loss=6.9923, lr=0.000044]Training:  68%|██████▊   | 265/391 [00:34<00:14,  8.84it/s, loss=6.8297, lr=0.000053]Training:  68%|██████▊   | 265/391 [00:39<00:14,  8.84it/s, loss=6.6370, lr=0.000061]Training:  91%|█████████ | 356/391 [00:40<00:03,  8.91it/s, loss=6.6370, lr=0.000061]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 01 | Time: 45s | T_Loss: 7.459 | V_Loss: 6.738 | BLEU: 0.11
 >> Sample: <s>The US, the US of the US of the US of the US of the US of the US of the US of the US of the US of the US of the US of the US of the US of the US of the world’s
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=6.4853, lr=0.000068]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=6.3472, lr=0.000077]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.87it/s, loss=6.3472, lr=0.000077]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.87it/s, loss=6.2625, lr=0.000086]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.87it/s, loss=6.1725, lr=0.000095]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.00it/s, loss=6.1725, lr=0.000095]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.00it/s, loss=6.0527, lr=0.000103]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.00it/s, loss=5.9804, lr=0.000112]Training:  70%|██████▉   | 272/391 [00:30<00:13,  9.03it/s, loss=5.9804, lr=0.000112]Training:  70%|██████▉   | 272/391 [00:33<00:13,  9.03it/s, loss=5.9672, lr=0.000121]Training:  70%|██████▉   | 272/391 [00:39<00:13,  9.03it/s, loss=5.8134, lr=0.000130]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.93it/s, loss=5.8134, lr=0.000130]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 02 | Time: 45s | T_Loss: 6.093 | V_Loss: 6.069 | BLEU: 0.11
 >> Sample: <s>The US has been a new piny of the COC, and the COC, the COEs, the COEs, the COEs, the COEs of the COE
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=5.7551, lr=0.000137]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=5.6398, lr=0.000146]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.92it/s, loss=5.6398, lr=0.000146]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.92it/s, loss=5.6274, lr=0.000154]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.92it/s, loss=5.4661, lr=0.000163]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.88it/s, loss=5.4661, lr=0.000163]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.88it/s, loss=5.4956, lr=0.000172]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.88it/s, loss=5.4092, lr=0.000180]Training:  69%|██████▉   | 269/391 [00:30<00:13,  8.85it/s, loss=5.4092, lr=0.000180]Training:  69%|██████▉   | 269/391 [00:33<00:13,  8.85it/s, loss=5.2792, lr=0.000189]Training:  69%|██████▉   | 269/391 [00:39<00:13,  8.85it/s, loss=5.2721, lr=0.000198]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.85it/s, loss=5.2721, lr=0.000198]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 03 | Time: 45s | T_Loss: 5.497 | V_Loss: 5.575 | BLEU: 0.16
 >> Sample: <s>The first time of the Bla, the Bla’s Mana, the Bla, the Bla, has been a new boldery.</s> of the world’s bottomy.
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=5.2109, lr=0.000205]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=5.1155, lr=0.000214]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.80it/s, loss=5.1155, lr=0.000214]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.80it/s, loss=5.1008, lr=0.000223]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.80it/s, loss=5.1225, lr=0.000231]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.85it/s, loss=5.1225, lr=0.000231]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.85it/s, loss=5.0823, lr=0.000240]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.85it/s, loss=4.9752, lr=0.000249]Training:  69%|██████▉   | 269/391 [00:30<00:13,  8.93it/s, loss=4.9752, lr=0.000249]Training:  69%|██████▉   | 269/391 [00:33<00:13,  8.93it/s, loss=5.0212, lr=0.000257]Training:  69%|██████▉   | 269/391 [00:39<00:13,  8.93it/s, loss=4.9573, lr=0.000266]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.97it/s, loss=4.9573, lr=0.000266]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 04 | Time: 45s | T_Loss: 5.056 | V_Loss: 5.298 | BLEU: 0.61
 >> Sample: <s>The US has been used to be a bombing, and the body of the body-productober, which has been used to be used to be a body-driven body.</s>ed.</s>
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=4.8832, lr=0.000273]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=4.8349, lr=0.000282]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.86it/s, loss=4.8349, lr=0.000282]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.86it/s, loss=4.8124, lr=0.000291]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.86it/s, loss=4.7197, lr=0.000300]Training:  46%|████▌     | 180/391 [00:20<00:23,  9.00it/s, loss=4.7197, lr=0.000300]Training:  46%|████▌     | 180/391 [00:22<00:23,  9.00it/s, loss=4.6805, lr=0.000308]Training:  46%|████▌     | 180/391 [00:27<00:23,  9.00it/s, loss=4.6855, lr=0.000317]Training:  69%|██████▉   | 271/391 [00:30<00:13,  9.01it/s, loss=4.6855, lr=0.000317]Training:  69%|██████▉   | 271/391 [00:33<00:13,  9.01it/s, loss=4.6565, lr=0.000326]Training:  69%|██████▉   | 271/391 [00:39<00:13,  9.01it/s, loss=4.6626, lr=0.000335]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.93it/s, loss=4.6626, lr=0.000335]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 05 | Time: 45s | T_Loss: 4.721 | V_Loss: 5.074 | BLEU: 0.97
 >> Sample: <s>The COC’s Facebook, the Twitter of the Talibet, has been a bolded, and the public-pricketty-service-service-service-
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=4.6070, lr=0.000342]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=4.4797, lr=0.000350]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.87it/s, loss=4.4797, lr=0.000350]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.87it/s, loss=4.4249, lr=0.000359]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.87it/s, loss=4.4318, lr=0.000368]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.98it/s, loss=4.4318, lr=0.000368]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.98it/s, loss=4.4729, lr=0.000377]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.98it/s, loss=4.3774, lr=0.000385]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.96it/s, loss=4.3774, lr=0.000385]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.96it/s, loss=4.3463, lr=0.000394]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.96it/s, loss=4.3098, lr=0.000403]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.96it/s, loss=4.3098, lr=0.000403]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 06 | Time: 45s | T_Loss: 4.431 | V_Loss: 4.880 | BLEU: 0.94
 >> Sample: <s>In the last week, the Petty’s Peter-price Price Price’s Fe Policy Institute, the US Department of the Policy’s high-public P
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=4.2723, lr=0.000410]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=4.2259, lr=0.000419]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.04it/s, loss=4.2259, lr=0.000419]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.04it/s, loss=4.2079, lr=0.000427]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.04it/s, loss=4.1977, lr=0.000436]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.88it/s, loss=4.1977, lr=0.000436]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.88it/s, loss=4.2274, lr=0.000445]Training:  47%|████▋     | 182/391 [00:28<00:23,  8.88it/s, loss=4.2396, lr=0.000454]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.88it/s, loss=4.2396, lr=0.000454]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.88it/s, loss=4.1593, lr=0.000462]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.88it/s, loss=4.1762, lr=0.000471]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.94it/s, loss=4.1762, lr=0.000471]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 07 | Time: 45s | T_Loss: 4.221 | V_Loss: 4.721 | BLEU: 1.60
 >> Sample: <s>Last week, the Petro-American Petrice Center for Acticine’s housing was released on the footpril, which has led to a stalemale of the footpril
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=4.0319, lr=0.000478]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.9981, lr=0.000487]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.05it/s, loss=3.9981, lr=0.000487]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.05it/s, loss=4.0646, lr=0.000496]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.05it/s, loss=4.0973, lr=0.000505]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.98it/s, loss=4.0973, lr=0.000505]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.98it/s, loss=4.1154, lr=0.000513]Training:  47%|████▋     | 182/391 [00:27<00:23,  8.98it/s, loss=4.0616, lr=0.000522]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.97it/s, loss=4.0616, lr=0.000522]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.97it/s, loss=4.0577, lr=0.000531]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.97it/s, loss=3.9544, lr=0.000539]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.93it/s, loss=3.9544, lr=0.000539]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 08 | Time: 45s | T_Loss: 4.059 | V_Loss: 4.603 | BLEU: 1.65
 >> Sample: <s>Last week, the Great Deputy Himalsein’s mastery was straightforward, and the stock-rights debate about the country’s mastery.</s>, the country’s mur
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.9544, lr=0.000547]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.8815, lr=0.000555]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.69it/s, loss=3.8815, lr=0.000555]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.69it/s, loss=3.8957, lr=0.000564]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.69it/s, loss=3.8873, lr=0.000573]Training:  45%|████▌     | 177/391 [00:20<00:24,  8.75it/s, loss=3.8873, lr=0.000573]Training:  45%|████▌     | 177/391 [00:22<00:24,  8.75it/s, loss=3.8506, lr=0.000582]Training:  45%|████▌     | 177/391 [00:28<00:24,  8.75it/s, loss=3.9613, lr=0.000590]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.88it/s, loss=3.9613, lr=0.000590]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.88it/s, loss=3.9312, lr=0.000599]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.88it/s, loss=3.9190, lr=0.000608]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.99it/s, loss=3.9190, lr=0.000608]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 09 | Time: 45s | T_Loss: 3.924 | V_Loss: 4.538 | BLEU: 1.76
 >> Sample: <s>Last week, the Cuban High-food Food Food Act, which triggered a sharp drop in the country’s foreign-policy homes, triggering a sharply hypotic brain
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.7439, lr=0.000615]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.7753, lr=0.000624]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.11it/s, loss=3.7753, lr=0.000624]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.11it/s, loss=3.7995, lr=0.000632]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.11it/s, loss=3.8325, lr=0.000641]Training:  47%|████▋     | 184/391 [00:20<00:23,  8.98it/s, loss=3.8325, lr=0.000641]Training:  47%|████▋     | 184/391 [00:22<00:23,  8.98it/s, loss=3.8006, lr=0.000650]Training:  47%|████▋     | 184/391 [00:27<00:23,  8.98it/s, loss=3.8120, lr=0.000659]Training:  70%|███████   | 274/391 [00:30<00:13,  8.97it/s, loss=3.8120, lr=0.000659]Training:  70%|███████   | 274/391 [00:33<00:13,  8.97it/s, loss=3.7638, lr=0.000667]Training:  70%|███████   | 274/391 [00:39<00:13,  8.97it/s, loss=3.8372, lr=0.000676]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.94it/s, loss=3.8372, lr=0.000676]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 10 | Time: 44s | T_Loss: 3.803 | V_Loss: 4.432 | BLEU: 2.11
 >> Sample: <s>Last week, the Cuba High-based High-based AMR, which triggered a sharply steady paper on the country’s property, triggering a dramatic debate on the hyp
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.6375, lr=0.000683]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.7564, lr=0.000692]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.88it/s, loss=3.7564, lr=0.000692]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.88it/s, loss=3.7143, lr=0.000698]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.88it/s, loss=3.7819, lr=0.000694]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.95it/s, loss=3.7819, lr=0.000694]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.95it/s, loss=3.6662, lr=0.000689]Training:  46%|████▌     | 179/391 [00:28<00:23,  8.95it/s, loss=3.6838, lr=0.000685]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.99it/s, loss=3.6838, lr=0.000685]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.99it/s, loss=3.6651, lr=0.000681]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.99it/s, loss=3.6666, lr=0.000677]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.95it/s, loss=3.6666, lr=0.000677]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 11 | Time: 44s | T_Loss: 3.696 | V_Loss: 4.349 | BLEU: 2.37
 >> Sample: <s>Last week, the Cuberian Home Amazon, a ceasefire, has triggered a sharp debate about the country’s output to be sold.</s> the time is being discussed.</s> the
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.5518, lr=0.000674]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.5824, lr=0.000670]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=3.5824, lr=0.000670]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=3.5687, lr=0.000666]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.97it/s, loss=3.6323, lr=0.000662]Training:  47%|████▋     | 182/391 [00:20<00:22,  9.09it/s, loss=3.6323, lr=0.000662]Training:  47%|████▋     | 182/391 [00:22<00:22,  9.09it/s, loss=3.5620, lr=0.000659]Training:  47%|████▋     | 182/391 [00:27<00:22,  9.09it/s, loss=3.5389, lr=0.000655]Training:  70%|███████   | 274/391 [00:30<00:13,  8.99it/s, loss=3.5389, lr=0.000655]Training:  70%|███████   | 274/391 [00:33<00:13,  8.99it/s, loss=3.5453, lr=0.000651]Training:  70%|███████   | 274/391 [00:39<00:13,  8.99it/s, loss=3.5831, lr=0.000648]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.91it/s, loss=3.5831, lr=0.000648]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 12 | Time: 45s | T_Loss: 3.581 | V_Loss: 4.254 | BLEU: 2.43
 >> Sample: <s>Last week, the Cuba’s film for the Technocracy, triggered a debate about the loss of property in the country.</s> the debate on the hotels of the home.</s> the US
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.4417, lr=0.000645]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.4861, lr=0.000642]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=3.4861, lr=0.000642]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=3.5225, lr=0.000638]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.97it/s, loss=3.5070, lr=0.000635]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.92it/s, loss=3.5070, lr=0.000635]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.92it/s, loss=3.4686, lr=0.000632]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.92it/s, loss=3.5316, lr=0.000629]Training:  69%|██████▉   | 269/391 [00:30<00:13,  8.90it/s, loss=3.5316, lr=0.000629]Training:  69%|██████▉   | 269/391 [00:33<00:13,  8.90it/s, loss=3.5084, lr=0.000625]Training:  69%|██████▉   | 269/391 [00:39<00:13,  8.90it/s, loss=3.5315, lr=0.000622]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.89it/s, loss=3.5315, lr=0.000622]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 13 | Time: 45s | T_Loss: 3.482 | V_Loss: 4.184 | BLEU: 2.92
 >> Sample: <s>Last week, the Cuba-based High-Leave Time Airbus, triggered a debate about the sharp spotlight on the country’s output rate.</s> the world’s dramatic h
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.3258, lr=0.000620]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.3747, lr=0.000617]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.78it/s, loss=3.3747, lr=0.000617]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.78it/s, loss=3.4474, lr=0.000614]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.78it/s, loss=3.3658, lr=0.000611]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.87it/s, loss=3.3658, lr=0.000611]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.87it/s, loss=3.3990, lr=0.000608]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.87it/s, loss=3.3811, lr=0.000605]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.86it/s, loss=3.3811, lr=0.000605]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.86it/s, loss=3.4091, lr=0.000602]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.86it/s, loss=3.4437, lr=0.000600]Training:  91%|█████████▏| 357/391 [00:40<00:03,  8.84it/s, loss=3.4437, lr=0.000600]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 14 | Time: 45s | T_Loss: 3.396 | V_Loss: 4.112 | BLEU: 3.51
 >> Sample: <s>Last week, the Cuba’s dramatic hotter of the American homeowner Amendment, triggering debate about the country’s sharp-hot-saving property-rights abduction rate
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.2585, lr=0.000597]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.3163, lr=0.000595]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=3.3163, lr=0.000595]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=3.3750, lr=0.000592]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=3.3735, lr=0.000589]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.86it/s, loss=3.3735, lr=0.000589]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.86it/s, loss=3.3455, lr=0.000587]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.86it/s, loss=3.2412, lr=0.000584]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.90it/s, loss=3.2412, lr=0.000584]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.90it/s, loss=3.3909, lr=0.000582]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.90it/s, loss=3.3422, lr=0.000579]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.91it/s, loss=3.3422, lr=0.000579]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 15 | Time: 45s | T_Loss: 3.323 | V_Loss: 4.085 | BLEU: 3.21
 >> Sample: <s>Last week, the Cuba Houssemblyn of the Coca Home, a hotel on the holiday of the country’s sharp-high-speed holiday rate.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.2016, lr=0.000577]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.2007, lr=0.000575]Training:  23%|██▎       | 89/391 [00:10<00:33,  8.90it/s, loss=3.2007, lr=0.000575]Training:  23%|██▎       | 89/391 [00:11<00:33,  8.90it/s, loss=3.1848, lr=0.000572]Training:  23%|██▎       | 89/391 [00:16<00:33,  8.90it/s, loss=3.2090, lr=0.000570]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.92it/s, loss=3.2090, lr=0.000570]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.92it/s, loss=3.3000, lr=0.000567]Training:  46%|████▌     | 179/391 [00:28<00:23,  8.92it/s, loss=3.2159, lr=0.000565]Training:  69%|██████▉   | 269/391 [00:30<00:13,  8.90it/s, loss=3.2159, lr=0.000565]Training:  69%|██████▉   | 269/391 [00:33<00:13,  8.90it/s, loss=3.2905, lr=0.000563]Training:  69%|██████▉   | 269/391 [00:39<00:13,  8.90it/s, loss=3.2860, lr=0.000561]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.93it/s, loss=3.2860, lr=0.000561]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 16 | Time: 45s | T_Loss: 3.259 | V_Loss: 4.028 | BLEU: 3.41
 >> Sample: <s>Last week, the Cuban Home Act of Justice, a hotel on the hospital, triggered a hypothetical discussion about the country’s output rate.</s> the table
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.1988, lr=0.000559]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.1638, lr=0.000556]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=3.1638, lr=0.000556]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=3.1129, lr=0.000554]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=3.2189, lr=0.000552]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.03it/s, loss=3.2189, lr=0.000552]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.03it/s, loss=3.2323, lr=0.000550]Training:  46%|████▋     | 181/391 [00:28<00:23,  9.03it/s, loss=3.2409, lr=0.000548]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.90it/s, loss=3.2409, lr=0.000548]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.90it/s, loss=3.2619, lr=0.000546]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.90it/s, loss=3.1995, lr=0.000544]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.96it/s, loss=3.1995, lr=0.000544]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 17 | Time: 45s | T_Loss: 3.201 | V_Loss: 4.005 | BLEU: 3.43
 >> Sample: <s>Last week, the Cuban Houssein’s Homey Trapy, which triggered a serious debate about the country’s property-rights abuses.</s> a holiday.</s> the
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.1166, lr=0.000542]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.2372, lr=0.000540]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.01it/s, loss=3.2372, lr=0.000540]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.01it/s, loss=3.1522, lr=0.000538]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.01it/s, loss=3.1406, lr=0.000536]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.99it/s, loss=3.1406, lr=0.000536]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.99it/s, loss=3.1918, lr=0.000534]Training:  47%|████▋     | 182/391 [00:27<00:23,  8.99it/s, loss=3.1550, lr=0.000532]Training:  70%|██████▉   | 273/391 [00:30<00:13,  9.04it/s, loss=3.1550, lr=0.000532]Training:  70%|██████▉   | 273/391 [00:33<00:13,  9.04it/s, loss=3.2192, lr=0.000530]Training:  70%|██████▉   | 273/391 [00:39<00:13,  9.04it/s, loss=3.1079, lr=0.000528]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.99it/s, loss=3.1079, lr=0.000528]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 18 | Time: 44s | T_Loss: 3.150 | V_Loss: 3.971 | BLEU: 3.69
 >> Sample: <s>Last week, the Cuba Houssembly of the Coca Home Anturner, unexpectedly trigger a serious discussion about the sharp spotlight on the country’s property-rights
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.1018, lr=0.000527]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.0995, lr=0.000525]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.80it/s, loss=3.0995, lr=0.000525]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.80it/s, loss=3.0991, lr=0.000523]Training:  23%|██▎       | 88/391 [00:16<00:34,  8.80it/s, loss=3.0615, lr=0.000521]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.99it/s, loss=3.0615, lr=0.000521]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.99it/s, loss=3.1381, lr=0.000519]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.99it/s, loss=3.0749, lr=0.000518]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.93it/s, loss=3.0749, lr=0.000518]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.93it/s, loss=3.1250, lr=0.000516]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.93it/s, loss=3.0943, lr=0.000514]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.81it/s, loss=3.0943, lr=0.000514]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 19 | Time: 45s | T_Loss: 3.104 | V_Loss: 3.961 | BLEU: 3.69
 >> Sample: <s>Last week, the Cuban Home Primacy Aporture of Foods, triggered a strong debate about the country’s massive loss of property.</s>ed the tremendous debate.</s> with
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.0342, lr=0.000513]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.0129, lr=0.000511]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.87it/s, loss=3.0129, lr=0.000511]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.87it/s, loss=3.0698, lr=0.000509]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.87it/s, loss=3.0143, lr=0.000508]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.84it/s, loss=3.0143, lr=0.000508]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.84it/s, loss=3.0486, lr=0.000506]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.84it/s, loss=3.1025, lr=0.000504]Training:  68%|██████▊   | 267/391 [00:30<00:14,  8.82it/s, loss=3.1025, lr=0.000504]Training:  68%|██████▊   | 267/391 [00:33<00:14,  8.82it/s, loss=3.1160, lr=0.000503]Training:  68%|██████▊   | 267/391 [00:39<00:14,  8.82it/s, loss=3.0873, lr=0.000501]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.99it/s, loss=3.0873, lr=0.000501]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 20 | Time: 45s | T_Loss: 3.062 | V_Loss: 3.924 | BLEU: 4.22
 >> Sample: <s>Last week, the Cuban Home Travel in the US, the Homewoods of Home, triggered a dramatic debate about the country’s property-rights abundance rate.</s>,
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.9492, lr=0.000500]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=3.0340, lr=0.000498]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.92it/s, loss=3.0340, lr=0.000498]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.92it/s, loss=3.0222, lr=0.000497]Training:  23%|██▎       | 90/391 [00:17<00:33,  8.92it/s, loss=2.9553, lr=0.000495]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.89it/s, loss=2.9553, lr=0.000495]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.89it/s, loss=3.0789, lr=0.000493]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.89it/s, loss=3.0154, lr=0.000492]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.91it/s, loss=3.0154, lr=0.000492]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.91it/s, loss=3.0497, lr=0.000490]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.91it/s, loss=3.0728, lr=0.000489]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.97it/s, loss=3.0728, lr=0.000489]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 21 | Time: 44s | T_Loss: 3.023 | V_Loss: 3.920 | BLEU: 4.06
 >> Sample: <s>Last week, the Cuban Houssey Mechanism of the American Foreign Academy was intended to trigger a hypothetical discussion about the sharply absorbed rate of the
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=3.0256, lr=0.000488]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.9266, lr=0.000486]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.87it/s, loss=2.9266, lr=0.000486]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.87it/s, loss=2.9607, lr=0.000485]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.87it/s, loss=3.0157, lr=0.000483]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.02it/s, loss=3.0157, lr=0.000483]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.02it/s, loss=3.0152, lr=0.000482]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.02it/s, loss=2.9617, lr=0.000480]Training:  70%|██████▉   | 273/391 [00:30<00:13,  9.03it/s, loss=2.9617, lr=0.000480]Training:  70%|██████▉   | 273/391 [00:33<00:13,  9.03it/s, loss=3.0708, lr=0.000479]Training:  70%|██████▉   | 273/391 [00:39<00:13,  9.03it/s, loss=3.0574, lr=0.000478]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.94it/s, loss=3.0574, lr=0.000478]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 22 | Time: 44s | T_Loss: 2.988 | V_Loss: 3.904 | BLEU: 3.95
 >> Sample: <s>Last week, the Cuban Houssey Meeting of the American Home Private Meeting was delivered in a deliberate discussion about the country’s sharp-hot-
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.9143, lr=0.000476]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8933, lr=0.000475]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.94it/s, loss=2.8933, lr=0.000475]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.94it/s, loss=2.9197, lr=0.000474]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.94it/s, loss=2.9735, lr=0.000472]Training:  46%|████▋     | 181/391 [00:20<00:23,  8.99it/s, loss=2.9735, lr=0.000472]Training:  46%|████▋     | 181/391 [00:22<00:23,  8.99it/s, loss=2.9678, lr=0.000471]Training:  46%|████▋     | 181/391 [00:27<00:23,  8.99it/s, loss=2.9548, lr=0.000470]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.95it/s, loss=2.9548, lr=0.000470]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.95it/s, loss=2.9558, lr=0.000468]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.95it/s, loss=2.9923, lr=0.000467]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.93it/s, loss=2.9923, lr=0.000467]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 23 | Time: 45s | T_Loss: 2.955 | V_Loss: 3.872 | BLEU: 4.27
 >> Sample: <s>Last week, the Cuban Houssey Travel suspended the temporary ceasefire of the American Home, triggering a dramatic discussion of the country’s dramatic loss of output.
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.8801, lr=0.000466]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8959, lr=0.000465]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.77it/s, loss=2.8959, lr=0.000465]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.77it/s, loss=2.9341, lr=0.000463]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.77it/s, loss=2.9610, lr=0.000462]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.87it/s, loss=2.9610, lr=0.000462]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.87it/s, loss=2.9608, lr=0.000461]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.87it/s, loss=2.9315, lr=0.000460]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.87it/s, loss=2.9315, lr=0.000460]Training:  69%|██████▊   | 268/391 [00:34<00:13,  8.87it/s, loss=2.9147, lr=0.000458]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.87it/s, loss=2.9386, lr=0.000457]Training:  91%|█████████▏| 357/391 [00:40<00:03,  8.87it/s, loss=2.9386, lr=0.000457]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 24 | Time: 45s | T_Loss: 2.925 | V_Loss: 3.865 | BLEU: 4.31
 >> Sample: <s>Last week, the Cuban Houssein’s Home Princeton Watergate Meetershed, in which surprisingly triggered a false discussion about the country’s sharp-
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.8879, lr=0.000456]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8703, lr=0.000455]Training:  23%|██▎       | 89/391 [00:10<00:33,  8.90it/s, loss=2.8703, lr=0.000455]Training:  23%|██▎       | 89/391 [00:11<00:33,  8.90it/s, loss=2.8634, lr=0.000454]Training:  23%|██▎       | 89/391 [00:16<00:33,  8.90it/s, loss=2.8135, lr=0.000453]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.95it/s, loss=2.8135, lr=0.000453]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.95it/s, loss=2.8848, lr=0.000451]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.95it/s, loss=2.9086, lr=0.000450]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.85it/s, loss=2.9086, lr=0.000450]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.85it/s, loss=2.9030, lr=0.000449]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.85it/s, loss=2.8957, lr=0.000448]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.85it/s, loss=2.8957, lr=0.000448]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 25 | Time: 45s | T_Loss: 2.897 | V_Loss: 3.847 | BLEU: 4.23
 >> Sample: <s>Last week, the Cuban Houssey Meeting of the American Home, the unexpected deliberately triggered a false discussion about the country’s dramatic loss of output
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.8273, lr=0.000447]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8455, lr=0.000446]Training:  23%|██▎       | 90/391 [00:10<00:33,  9.00it/s, loss=2.8455, lr=0.000446]Training:  23%|██▎       | 90/391 [00:11<00:33,  9.00it/s, loss=2.8170, lr=0.000445]Training:  23%|██▎       | 90/391 [00:16<00:33,  9.00it/s, loss=2.8257, lr=0.000444]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.03it/s, loss=2.8257, lr=0.000444]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.03it/s, loss=2.8858, lr=0.000442]Training:  46%|████▋     | 181/391 [00:28<00:23,  9.03it/s, loss=2.8922, lr=0.000441]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.95it/s, loss=2.8922, lr=0.000441]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.95it/s, loss=2.9215, lr=0.000440]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.95it/s, loss=2.8581, lr=0.000439]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.91it/s, loss=2.8581, lr=0.000439]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 26 | Time: 45s | T_Loss: 2.870 | V_Loss: 3.847 | BLEU: 4.30
 >> Sample: <s>Last week, the Cuban Homewood movie was temporarily suspended, triggering a false discussion of the country’s dramatic loss of output.</s> the same time.</s> the same
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.8045, lr=0.000438]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8420, lr=0.000437]Training:  23%|██▎       | 89/391 [00:10<00:33,  8.90it/s, loss=2.8420, lr=0.000437]Training:  23%|██▎       | 89/391 [00:11<00:33,  8.90it/s, loss=2.8522, lr=0.000436]Training:  23%|██▎       | 89/391 [00:16<00:33,  8.90it/s, loss=2.8612, lr=0.000435]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.95it/s, loss=2.8612, lr=0.000435]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.95it/s, loss=2.8603, lr=0.000434]Training:  46%|████▌     | 179/391 [00:27<00:23,  8.95it/s, loss=2.7989, lr=0.000433]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.99it/s, loss=2.7989, lr=0.000433]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.99it/s, loss=2.8145, lr=0.000432]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.99it/s, loss=2.8918, lr=0.000431]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.92it/s, loss=2.8918, lr=0.000431]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 27 | Time: 45s | T_Loss: 2.845 | V_Loss: 3.836 | BLEU: 4.46
 >> Sample: <s>Last week, the ancient Houssein Academy of Fannie Mae, in which the US was delivered a false discussion of the country’s dramatic loss of output.</s>
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.7969, lr=0.000430]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.8222, lr=0.000429]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.88it/s, loss=2.8222, lr=0.000429]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.88it/s, loss=2.7607, lr=0.000428]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.88it/s, loss=2.8132, lr=0.000427]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.82it/s, loss=2.8132, lr=0.000427]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.82it/s, loss=2.8837, lr=0.000426]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.82it/s, loss=2.8384, lr=0.000425]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.87it/s, loss=2.8384, lr=0.000425]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.87it/s, loss=2.8318, lr=0.000424]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.87it/s, loss=2.8831, lr=0.000423]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.89it/s, loss=2.8831, lr=0.000423]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 28 | Time: 45s | T_Loss: 2.821 | V_Loss: 3.827 | BLEU: 4.42
 >> Sample: <s>Last week, the Cocaust Bacterium on Foreign Houssey, the accidential ceasefire, triggered a false discussion about the country’s output rate.</s> the same
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.7582, lr=0.000422]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.7610, lr=0.000421]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.82it/s, loss=2.7610, lr=0.000421]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.82it/s, loss=2.7460, lr=0.000420]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.82it/s, loss=2.7599, lr=0.000419]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.94it/s, loss=2.7599, lr=0.000419]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.94it/s, loss=2.8019, lr=0.000419]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.94it/s, loss=2.8067, lr=0.000418]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.95it/s, loss=2.8067, lr=0.000418]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.95it/s, loss=2.8354, lr=0.000417]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.95it/s, loss=2.8442, lr=0.000416]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.92it/s, loss=2.8442, lr=0.000416]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 29 | Time: 45s | T_Loss: 2.798 | V_Loss: 3.806 | BLEU: 4.52
 >> Sample: <s>Last week, the Cuban Home Academy of Foreign Academy stopped the temporarily, unintended discussion of the country’s dramatic loss of output.</s> the
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.7709, lr=0.000415]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.7437, lr=0.000414]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.93it/s, loss=2.7437, lr=0.000414]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.93it/s, loss=2.7642, lr=0.000413]Training:  23%|██▎       | 90/391 [00:17<00:33,  8.93it/s, loss=2.7941, lr=0.000412]Training:  46%|████▌     | 180/391 [00:20<00:24,  8.78it/s, loss=2.7941, lr=0.000412]Training:  46%|████▌     | 180/391 [00:22<00:24,  8.78it/s, loss=2.8223, lr=0.000411]Training:  46%|████▌     | 180/391 [00:28<00:24,  8.78it/s, loss=2.7504, lr=0.000411]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.93it/s, loss=2.7504, lr=0.000411]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.93it/s, loss=2.7736, lr=0.000410]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.93it/s, loss=2.7485, lr=0.000409]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.96it/s, loss=2.7485, lr=0.000409]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 30 | Time: 45s | T_Loss: 2.778 | V_Loss: 3.819 | BLEU: 4.59
 >> Sample: <s>Last week, the Cuban Houssein’s Meeting of Family Planeting, in which surprisingly triggered a hypothetical discussion about the country’s sharply rising
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.7469, lr=0.000408]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.7308, lr=0.000407]Training:  23%|██▎       | 91/391 [00:10<00:33,  8.99it/s, loss=2.7308, lr=0.000407]Training:  23%|██▎       | 91/391 [00:11<00:33,  8.99it/s, loss=2.6839, lr=0.000406]Training:  23%|██▎       | 91/391 [00:17<00:33,  8.99it/s, loss=2.7375, lr=0.000405]Training:  46%|████▋     | 181/391 [00:20<00:23,  8.81it/s, loss=2.7375, lr=0.000405]Training:  46%|████▋     | 181/391 [00:22<00:23,  8.81it/s, loss=2.7849, lr=0.000405]Training:  46%|████▋     | 181/391 [00:28<00:23,  8.81it/s, loss=2.7931, lr=0.000404]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.84it/s, loss=2.7931, lr=0.000404]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.84it/s, loss=2.7636, lr=0.000403]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.84it/s, loss=2.7715, lr=0.000402]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.85it/s, loss=2.7715, lr=0.000402]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 31 | Time: 45s | T_Loss: 2.758 | V_Loss: 3.795 | BLEU: 4.77
 >> Sample: <s>Last week, the Cuban Houssein’s Mike Post was deliberately swept, triggering a false discussion about the country’s sharp-hot-hot-for
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.6850, lr=0.000401]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6639, lr=0.000401]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=2.6639, lr=0.000401]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=2.7042, lr=0.000400]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.97it/s, loss=2.7226, lr=0.000399]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.92it/s, loss=2.7226, lr=0.000399]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.92it/s, loss=2.6845, lr=0.000398]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.92it/s, loss=2.7641, lr=0.000397]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.98it/s, loss=2.7641, lr=0.000397]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.98it/s, loss=2.7982, lr=0.000397]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.98it/s, loss=2.7575, lr=0.000396]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.95it/s, loss=2.7575, lr=0.000396]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 32 | Time: 45s | T_Loss: 2.738 | V_Loss: 3.786 | BLEU: 4.78
 >> Sample: <s>Last week, the Cuban Home’s Measkin Academy was temporarily suspended, triggering a hypothetical discussion about the country’s production-treat
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.6785, lr=0.000395]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.7268, lr=0.000394]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.80it/s, loss=2.7268, lr=0.000394]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.80it/s, loss=2.6625, lr=0.000394]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.80it/s, loss=2.7137, lr=0.000393]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.83it/s, loss=2.7137, lr=0.000393]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.83it/s, loss=2.7048, lr=0.000392]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.83it/s, loss=2.7435, lr=0.000391]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.88it/s, loss=2.7435, lr=0.000391]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.88it/s, loss=2.7849, lr=0.000390]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.88it/s, loss=2.7520, lr=0.000390]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.91it/s, loss=2.7520, lr=0.000390]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 33 | Time: 45s | T_Loss: 2.720 | V_Loss: 3.777 | BLEU: 4.67
 >> Sample: <s>Last week, the Cuban Houssein Meeting of the American Home, unexpectedly triggered a false discussion about the sharp-hot-for-take-up of the
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.6282, lr=0.000389]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6468, lr=0.000388]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.87it/s, loss=2.6468, lr=0.000388]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.87it/s, loss=2.6573, lr=0.000388]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.87it/s, loss=2.7566, lr=0.000387]Training:  46%|████▌     | 178/391 [00:20<00:23,  8.88it/s, loss=2.7566, lr=0.000387]Training:  46%|████▌     | 178/391 [00:22<00:23,  8.88it/s, loss=2.7026, lr=0.000386]Training:  46%|████▌     | 178/391 [00:28<00:23,  8.88it/s, loss=2.6963, lr=0.000385]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.90it/s, loss=2.6963, lr=0.000385]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.90it/s, loss=2.7397, lr=0.000385]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.90it/s, loss=2.7516, lr=0.000384]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.88it/s, loss=2.7516, lr=0.000384]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 34 | Time: 45s | T_Loss: 2.703 | V_Loss: 3.780 | BLEU: 4.86
 >> Sample: <s>Last week, the ancient Houssein Academy of Family Planting, in which the American Foreign Academy delivered a hypothetical discussion about the
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.7282, lr=0.000383]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6892, lr=0.000383]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.83it/s, loss=2.6892, lr=0.000383]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.83it/s, loss=2.7237, lr=0.000382]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.83it/s, loss=2.6491, lr=0.000381]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.85it/s, loss=2.6491, lr=0.000381]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.85it/s, loss=2.7154, lr=0.000380]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.85it/s, loss=2.6969, lr=0.000380]Training:  68%|██████▊   | 267/391 [00:30<00:13,  8.87it/s, loss=2.6969, lr=0.000380]Training:  68%|██████▊   | 267/391 [00:33<00:13,  8.87it/s, loss=2.7211, lr=0.000379]Training:  68%|██████▊   | 267/391 [00:39<00:13,  8.87it/s, loss=2.7108, lr=0.000378]Training:  92%|█████████▏| 358/391 [00:40<00:03,  8.93it/s, loss=2.7108, lr=0.000378]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 35 | Time: 45s | T_Loss: 2.686 | V_Loss: 3.781 | BLEU: 4.52
 >> Sample: <s>Last week, the ancient Houssein Antarctica Meeting of Foreign Antarct (TA), deliberately triggered a hypothetical discussion of
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.6120, lr=0.000378]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6790, lr=0.000377]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.96it/s, loss=2.6790, lr=0.000377]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.96it/s, loss=2.6226, lr=0.000376]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.96it/s, loss=2.6811, lr=0.000376]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.97it/s, loss=2.6811, lr=0.000376]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.97it/s, loss=2.7034, lr=0.000375]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.97it/s, loss=2.6460, lr=0.000374]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.94it/s, loss=2.6460, lr=0.000374]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.94it/s, loss=2.6981, lr=0.000374]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.94it/s, loss=2.7114, lr=0.000373]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.93it/s, loss=2.7114, lr=0.000373]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 36 | Time: 45s | T_Loss: 2.670 | V_Loss: 3.774 | BLEU: 4.54
 >> Sample: <s>Last week, the ancient Foreign Measures Traveled the Post, in which the surprise was triggered a false discussion of the country’s property rate.</s>.</s>,
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5911, lr=0.000372]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6406, lr=0.000372]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.07it/s, loss=2.6406, lr=0.000372]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.07it/s, loss=2.6422, lr=0.000371]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.07it/s, loss=2.6615, lr=0.000371]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.00it/s, loss=2.6615, lr=0.000371]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.00it/s, loss=2.6632, lr=0.000370]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.00it/s, loss=2.6453, lr=0.000369]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.97it/s, loss=2.6453, lr=0.000369]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.97it/s, loss=2.7393, lr=0.000369]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.97it/s, loss=2.7326, lr=0.000368]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.91it/s, loss=2.7326, lr=0.000368]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 37 | Time: 45s | T_Loss: 2.656 | V_Loss: 3.767 | BLEU: 5.06
 >> Sample: <s>Last week, the ancient Houssein Mechanism of American Housing, in which the unexpected spectacular debate about the sharp rewards of the country’s output have been false
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5828, lr=0.000367]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6313, lr=0.000367]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.00it/s, loss=2.6313, lr=0.000367]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.00it/s, loss=2.6836, lr=0.000366]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.00it/s, loss=2.5481, lr=0.000366]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.94it/s, loss=2.5481, lr=0.000366]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.94it/s, loss=2.6837, lr=0.000365]Training:  47%|████▋     | 182/391 [00:27<00:23,  8.94it/s, loss=2.6600, lr=0.000364]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.96it/s, loss=2.6600, lr=0.000364]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.96it/s, loss=2.6415, lr=0.000364]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.96it/s, loss=2.6844, lr=0.000363]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.99it/s, loss=2.6844, lr=0.000363]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 38 | Time: 44s | T_Loss: 2.641 | V_Loss: 3.753 | BLEU: 5.08
 >> Sample: <s>Last week, the ancient Foreign Academy of Food and Family Plant was delayed, triggering a false discussion about the country’s sharply rising property rate.
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5835, lr=0.000363]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6251, lr=0.000362]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.78it/s, loss=2.6251, lr=0.000362]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.78it/s, loss=2.6044, lr=0.000361]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.78it/s, loss=2.6609, lr=0.000361]Training:  45%|████▌     | 177/391 [00:20<00:24,  8.83it/s, loss=2.6609, lr=0.000361]Training:  45%|████▌     | 177/391 [00:22<00:24,  8.83it/s, loss=2.6280, lr=0.000360]Training:  45%|████▌     | 177/391 [00:28<00:24,  8.83it/s, loss=2.6831, lr=0.000360]Training:  68%|██████▊   | 267/391 [00:30<00:13,  8.90it/s, loss=2.6831, lr=0.000360]Training:  68%|██████▊   | 267/391 [00:33<00:13,  8.90it/s, loss=2.6292, lr=0.000359]Training:  68%|██████▊   | 267/391 [00:39<00:13,  8.90it/s, loss=2.6609, lr=0.000358]Training:  91%|█████████▏| 357/391 [00:40<00:03,  8.90it/s, loss=2.6609, lr=0.000358]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 39 | Time: 45s | T_Loss: 2.626 | V_Loss: 3.768 | BLEU: 4.71
 >> Sample: <s>Last week, the ancient Homewood movie stopped the temporary ceasefire, triggering a hypothetical discussion about the country’s surging property-productivity rate
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5532, lr=0.000358]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5843, lr=0.000357]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.86it/s, loss=2.5843, lr=0.000357]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.86it/s, loss=2.5765, lr=0.000357]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.86it/s, loss=2.6247, lr=0.000356]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.03it/s, loss=2.6247, lr=0.000356]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.03it/s, loss=2.6796, lr=0.000356]Training:  46%|████▋     | 181/391 [00:28<00:23,  9.03it/s, loss=2.6332, lr=0.000355]Training:  70%|██████▉   | 273/391 [00:30<00:13,  8.91it/s, loss=2.6332, lr=0.000355]Training:  70%|██████▉   | 273/391 [00:33<00:13,  8.91it/s, loss=2.5975, lr=0.000354]Training:  70%|██████▉   | 273/391 [00:39<00:13,  8.91it/s, loss=2.6130, lr=0.000354]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.95it/s, loss=2.6130, lr=0.000354]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 40 | Time: 45s | T_Loss: 2.613 | V_Loss: 3.766 | BLEU: 4.72
 >> Sample: <s>Last week, the ancient Home Private Meetershed a temporary ceasefire, triggering a harsh debate about the country’s property-supply construction rate.</s>.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5640, lr=0.000353]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5789, lr=0.000353]Training:  23%|██▎       | 89/391 [00:10<00:33,  8.90it/s, loss=2.5789, lr=0.000353]Training:  23%|██▎       | 89/391 [00:11<00:33,  8.90it/s, loss=2.5943, lr=0.000352]Training:  23%|██▎       | 89/391 [00:16<00:33,  8.90it/s, loss=2.5964, lr=0.000352]Training:  46%|████▌     | 178/391 [00:20<00:23,  8.88it/s, loss=2.5964, lr=0.000352]Training:  46%|████▌     | 178/391 [00:22<00:23,  8.88it/s, loss=2.5761, lr=0.000351]Training:  46%|████▌     | 178/391 [00:28<00:23,  8.88it/s, loss=2.6276, lr=0.000351]Training:  68%|██████▊   | 267/391 [00:30<00:14,  8.83it/s, loss=2.6276, lr=0.000351]Training:  68%|██████▊   | 267/391 [00:34<00:14,  8.83it/s, loss=2.6035, lr=0.000350]Training:  68%|██████▊   | 267/391 [00:39<00:14,  8.83it/s, loss=2.6112, lr=0.000349]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.93it/s, loss=2.6112, lr=0.000349]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 41 | Time: 45s | T_Loss: 2.600 | V_Loss: 3.778 | BLEU: 4.79
 >> Sample: <s>Last week, the ancient homebuyer Microbes were temporarily halted, triggering a hypothetical discussion of the country’s property-supply construction rate.</s> a tem
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5722, lr=0.000349]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.6143, lr=0.000348]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=2.6143, lr=0.000348]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=2.5309, lr=0.000348]Training:  23%|██▎       | 90/391 [00:17<00:33,  8.97it/s, loss=2.5948, lr=0.000347]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.85it/s, loss=2.5948, lr=0.000347]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.85it/s, loss=2.5713, lr=0.000347]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.85it/s, loss=2.6221, lr=0.000346]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.91it/s, loss=2.6221, lr=0.000346]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.91it/s, loss=2.6014, lr=0.000346]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.91it/s, loss=2.6780, lr=0.000345]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.93it/s, loss=2.6780, lr=0.000345]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 42 | Time: 45s | T_Loss: 2.587 | V_Loss: 3.742 | BLEU: 4.71
 >> Sample: <s>Last week, the ancient Family Planet for Home, in which the American homeowner was deliberately delivered a hot spark discussion about the country’s property-product
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5503, lr=0.000345]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5738, lr=0.000344]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.85it/s, loss=2.5738, lr=0.000344]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.85it/s, loss=2.6196, lr=0.000344]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.85it/s, loss=2.5694, lr=0.000343]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.03it/s, loss=2.5694, lr=0.000343]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.03it/s, loss=2.6108, lr=0.000343]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.03it/s, loss=2.6398, lr=0.000342]Training:  70%|██████▉   | 273/391 [00:30<00:13,  8.96it/s, loss=2.6398, lr=0.000342]Training:  70%|██████▉   | 273/391 [00:33<00:13,  8.96it/s, loss=2.6208, lr=0.000342]Training:  70%|██████▉   | 273/391 [00:39<00:13,  8.96it/s, loss=2.6127, lr=0.000341]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.94it/s, loss=2.6127, lr=0.000341]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 43 | Time: 45s | T_Loss: 2.575 | V_Loss: 3.755 | BLEU: 5.00
 >> Sample: <s>Last week, the ancient American homebuyer McDonald’s was hacked, triggering a hypothetical discussion of the country’s property-surgered dramatic loss rate
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5055, lr=0.000341]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5519, lr=0.000340]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.78it/s, loss=2.5519, lr=0.000340]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.78it/s, loss=2.5241, lr=0.000340]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.78it/s, loss=2.5455, lr=0.000339]Training:  45%|████▌     | 177/391 [00:20<00:24,  8.85it/s, loss=2.5455, lr=0.000339]Training:  45%|████▌     | 177/391 [00:22<00:24,  8.85it/s, loss=2.5969, lr=0.000339]Training:  45%|████▌     | 177/391 [00:28<00:24,  8.85it/s, loss=2.5904, lr=0.000338]Training:  69%|██████▊   | 268/391 [00:30<00:13,  8.93it/s, loss=2.5904, lr=0.000338]Training:  69%|██████▊   | 268/391 [00:33<00:13,  8.93it/s, loss=2.5700, lr=0.000338]Training:  69%|██████▊   | 268/391 [00:39<00:13,  8.93it/s, loss=2.6132, lr=0.000337]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.92it/s, loss=2.6132, lr=0.000337]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 44 | Time: 45s | T_Loss: 2.563 | V_Loss: 3.741 | BLEU: 5.02
 >> Sample: <s>Last week, the ancient American homeowner Accord suspended a temporary ceasefire, triggering a hypothetical discussion about the country’s property rate.</s> a temporary h
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5147, lr=0.000337]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4773, lr=0.000336]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.80it/s, loss=2.4773, lr=0.000336]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.80it/s, loss=2.5295, lr=0.000336]Training:  23%|██▎       | 88/391 [00:16<00:34,  8.80it/s, loss=2.5565, lr=0.000335]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.93it/s, loss=2.5565, lr=0.000335]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.93it/s, loss=2.5646, lr=0.000335]Training:  46%|████▌     | 179/391 [00:28<00:23,  8.93it/s, loss=2.5646, lr=0.000335]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.94it/s, loss=2.5646, lr=0.000335]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.94it/s, loss=2.5615, lr=0.000334]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.94it/s, loss=2.6131, lr=0.000334]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.90it/s, loss=2.6131, lr=0.000334]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 45 | Time: 45s | T_Loss: 2.552 | V_Loss: 3.747 | BLEU: 4.94
 >> Sample: <s>Last week, the ancient American Foreign Mechanism, accidentally triggered a hot spotlight on the country’s output rate.</s> the temporary ceasefire.</s> all of the world
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4596, lr=0.000333]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5166, lr=0.000333]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=2.5166, lr=0.000333]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=2.5341, lr=0.000332]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=2.5368, lr=0.000332]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.96it/s, loss=2.5368, lr=0.000332]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.96it/s, loss=2.5429, lr=0.000331]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.96it/s, loss=2.5944, lr=0.000331]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.89it/s, loss=2.5944, lr=0.000331]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.89it/s, loss=2.5520, lr=0.000330]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.89it/s, loss=2.5445, lr=0.000330]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.93it/s, loss=2.5445, lr=0.000330]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 46 | Time: 45s | T_Loss: 2.540 | V_Loss: 3.747 | BLEU: 5.02
 >> Sample: <s>Last week, the ancient Foreign Mechanism (AFM), intended to trigger a hypothetical discussion about the yields of countries, was temporarily suspended.</s> the US
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5377, lr=0.000330]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4663, lr=0.000329]Training:  23%|██▎       | 88/391 [00:10<00:34,  8.75it/s, loss=2.4663, lr=0.000329]Training:  23%|██▎       | 88/391 [00:11<00:34,  8.75it/s, loss=2.5332, lr=0.000329]Training:  23%|██▎       | 88/391 [00:17<00:34,  8.75it/s, loss=2.5460, lr=0.000328]Training:  45%|████▌     | 177/391 [00:20<00:24,  8.83it/s, loss=2.5460, lr=0.000328]Training:  45%|████▌     | 177/391 [00:22<00:24,  8.83it/s, loss=2.5554, lr=0.000328]Training:  45%|████▌     | 177/391 [00:28<00:24,  8.83it/s, loss=2.5051, lr=0.000327]Training:  68%|██████▊   | 267/391 [00:30<00:13,  8.88it/s, loss=2.5051, lr=0.000327]Training:  68%|██████▊   | 267/391 [00:33<00:13,  8.88it/s, loss=2.5824, lr=0.000327]Training:  68%|██████▊   | 267/391 [00:39<00:13,  8.88it/s, loss=2.5985, lr=0.000326]Training:  68%|██████▊   | 267/391 [00:40<00:13,  8.88it/s, loss=2.5985, lr=0.000326]Training:  91%|█████████▏| 357/391 [00:40<00:03,  8.87it/s, loss=2.5985, lr=0.000326]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 47 | Time: 45s | T_Loss: 2.530 | V_Loss: 3.740 | BLEU: 5.19
 >> Sample: <s>Last week, the ancient Food and Family Measures, in which the intended race, triggered a false discussion of the country’s property-productivity rate.</s>
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4572, lr=0.000326]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4796, lr=0.000326]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.84it/s, loss=2.4796, lr=0.000326]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.84it/s, loss=2.4732, lr=0.000325]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.84it/s, loss=2.5045, lr=0.000325]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.95it/s, loss=2.5045, lr=0.000325]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.95it/s, loss=2.5161, lr=0.000324]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.95it/s, loss=2.6012, lr=0.000324]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.92it/s, loss=2.6012, lr=0.000324]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.92it/s, loss=2.5360, lr=0.000323]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.92it/s, loss=2.5317, lr=0.000323]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.91it/s, loss=2.5317, lr=0.000323]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 48 | Time: 45s | T_Loss: 2.519 | V_Loss: 3.748 | BLEU: 5.14
 >> Sample: <s>Last week, the ancient American Home Antarctica ceased a temporary ceasefire, triggering a false discussion of the country’s output rate.</s> all the way.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.5020, lr=0.000323]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4969, lr=0.000322]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.84it/s, loss=2.4969, lr=0.000322]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.84it/s, loss=2.4567, lr=0.000322]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.84it/s, loss=2.4500, lr=0.000321]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.95it/s, loss=2.4500, lr=0.000321]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.95it/s, loss=2.5065, lr=0.000321]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.95it/s, loss=2.5728, lr=0.000320]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.96it/s, loss=2.5728, lr=0.000320]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.96it/s, loss=2.5740, lr=0.000320]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.96it/s, loss=2.5185, lr=0.000320]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.97it/s, loss=2.5185, lr=0.000320]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 49 | Time: 44s | T_Loss: 2.509 | V_Loss: 3.734 | BLEU: 5.10
 >> Sample: <s>Last week, the ancient American Home Foreign Measures delayed a temporary cease, triggering a hypothetical discussion of the country’s property-rangered yields
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4515, lr=0.000319]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.5216, lr=0.000319]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=2.5216, lr=0.000319]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=2.5269, lr=0.000318]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=2.4531, lr=0.000318]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.96it/s, loss=2.4531, lr=0.000318]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.96it/s, loss=2.4892, lr=0.000318]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.96it/s, loss=2.4991, lr=0.000317]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.92it/s, loss=2.4991, lr=0.000317]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.92it/s, loss=2.4906, lr=0.000317]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.92it/s, loss=2.4593, lr=0.000316]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.96it/s, loss=2.4593, lr=0.000316]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 50 | Time: 44s | T_Loss: 2.500 | V_Loss: 3.743 | BLEU: 4.89
 >> Sample: <s>Last week, the ancient American homeowner McV stopped a temporary ceasefire, triggering a false discussion of the country’s property-productivity yield.</s> f
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4458, lr=0.000316]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4297, lr=0.000316]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.98it/s, loss=2.4297, lr=0.000316]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.98it/s, loss=2.4534, lr=0.000315]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.98it/s, loss=2.5041, lr=0.000315]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.91it/s, loss=2.5041, lr=0.000315]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.91it/s, loss=2.5380, lr=0.000314]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.91it/s, loss=2.5451, lr=0.000314]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.92it/s, loss=2.5451, lr=0.000314]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.92it/s, loss=2.5055, lr=0.000314]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.92it/s, loss=2.4544, lr=0.000313]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.91it/s, loss=2.4544, lr=0.000313]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 51 | Time: 45s | T_Loss: 2.490 | V_Loss: 3.740 | BLEU: 5.07
 >> Sample: <s>Last week, the ancient American Home Family McHA stopped spreading, unexpectedly triggering false discussions about the country’s property-surrence rate.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4537, lr=0.000313]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4499, lr=0.000313]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.98it/s, loss=2.4499, lr=0.000313]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.98it/s, loss=2.4724, lr=0.000312]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.98it/s, loss=2.4830, lr=0.000312]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.95it/s, loss=2.4830, lr=0.000312]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.95it/s, loss=2.4862, lr=0.000311]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.95it/s, loss=2.5032, lr=0.000311]Training:  69%|██████▉   | 271/391 [00:30<00:13,  8.98it/s, loss=2.5032, lr=0.000311]Training:  69%|██████▉   | 271/391 [00:33<00:13,  8.98it/s, loss=2.5113, lr=0.000311]Training:  69%|██████▉   | 271/391 [00:39<00:13,  8.98it/s, loss=2.4638, lr=0.000310]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.98it/s, loss=2.4638, lr=0.000310]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 52 | Time: 44s | T_Loss: 2.480 | V_Loss: 3.741 | BLEU: 5.14
 >> Sample: <s>Last week, the ancient Foreign McAT temporarily suspended, triggering a false discussion about the country’s property-productivity rate.</s>, in particular, was
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4537, lr=0.000310]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4209, lr=0.000310]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.98it/s, loss=2.4209, lr=0.000310]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.98it/s, loss=2.4793, lr=0.000309]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.98it/s, loss=2.4142, lr=0.000309]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.97it/s, loss=2.4142, lr=0.000309]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.97it/s, loss=2.5238, lr=0.000308]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.97it/s, loss=2.4716, lr=0.000308]Training:  70%|██████▉   | 272/391 [00:30<00:13,  9.03it/s, loss=2.4716, lr=0.000308]Training:  70%|██████▉   | 272/391 [00:33<00:13,  9.03it/s, loss=2.4879, lr=0.000308]Training:  70%|██████▉   | 272/391 [00:38<00:13,  9.03it/s, loss=2.4969, lr=0.000307]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.98it/s, loss=2.4969, lr=0.000307]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 53 | Time: 44s | T_Loss: 2.472 | V_Loss: 3.733 | BLEU: 4.99
 >> Sample: <s>Last week, the ancient American Home Foreign McA temporarily suspended, triggering false discussion about the country’s production-s sharp absolution rate.</s>.</s> a
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4400, lr=0.000307]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4403, lr=0.000307]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=2.4403, lr=0.000307]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=2.4313, lr=0.000306]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=2.4771, lr=0.000306]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.94it/s, loss=2.4771, lr=0.000306]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.94it/s, loss=2.4555, lr=0.000306]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.94it/s, loss=2.5033, lr=0.000305]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.93it/s, loss=2.5033, lr=0.000305]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.93it/s, loss=2.4644, lr=0.000305]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.93it/s, loss=2.5249, lr=0.000304]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.97it/s, loss=2.5249, lr=0.000304]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 54 | Time: 44s | T_Loss: 2.464 | V_Loss: 3.749 | BLEU: 5.27
 >> Sample: <s>Last week, the ancient American Home Family Meeting, an unexpected enthusiasm for false discussions about the country’s sharp-hypothesis rate of
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4268, lr=0.000304]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4254, lr=0.000304]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=2.4254, lr=0.000304]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=2.4755, lr=0.000303]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.97it/s, loss=2.5137, lr=0.000303]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.94it/s, loss=2.5137, lr=0.000303]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.94it/s, loss=2.4709, lr=0.000303]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.94it/s, loss=2.4525, lr=0.000302]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.95it/s, loss=2.4525, lr=0.000302]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.95it/s, loss=2.5340, lr=0.000302]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.95it/s, loss=2.4929, lr=0.000302]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.95it/s, loss=2.4929, lr=0.000302]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 55 | Time: 45s | T_Loss: 2.455 | V_Loss: 3.728 | BLEU: 5.27
 >> Sample: <s>Last week, the ancient American Home Foreign Measures delayed a temporary cease-fire, triggering false discussions about the country’s sharp-hypothesis
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3856, lr=0.000301]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4138, lr=0.000301]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.96it/s, loss=2.4138, lr=0.000301]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.96it/s, loss=2.4269, lr=0.000301]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.96it/s, loss=2.4617, lr=0.000300]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.04it/s, loss=2.4617, lr=0.000300]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.04it/s, loss=2.4734, lr=0.000300]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.04it/s, loss=2.4605, lr=0.000300]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.99it/s, loss=2.4605, lr=0.000300]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.99it/s, loss=2.4909, lr=0.000299]Training:  70%|██████▉   | 272/391 [00:38<00:13,  8.99it/s, loss=2.4597, lr=0.000299]Training:  93%|█████████▎| 365/391 [00:40<00:02,  9.08it/s, loss=2.4597, lr=0.000299]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 56 | Time: 44s | T_Loss: 2.447 | V_Loss: 3.732 | BLEU: 5.23
 >> Sample: <s>Last week, the ancient American Home Foreign McAT stopped slogan, surprising discussion of the false flags in home production.</s> also brought about the risk of a home
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4485, lr=0.000299]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4315, lr=0.000298]Training:  23%|██▎       | 90/391 [00:10<00:33,  9.00it/s, loss=2.4315, lr=0.000298]Training:  23%|██▎       | 90/391 [00:11<00:33,  9.00it/s, loss=2.4374, lr=0.000298]Training:  23%|██▎       | 90/391 [00:16<00:33,  9.00it/s, loss=2.4106, lr=0.000298]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.02it/s, loss=2.4106, lr=0.000298]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.02it/s, loss=2.4483, lr=0.000297]Training:  46%|████▋     | 181/391 [00:28<00:23,  9.02it/s, loss=2.4562, lr=0.000297]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.96it/s, loss=2.4562, lr=0.000297]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.96it/s, loss=2.4192, lr=0.000297]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.96it/s, loss=2.4442, lr=0.000296]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.98it/s, loss=2.4442, lr=0.000296]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 57 | Time: 44s | T_Loss: 2.439 | V_Loss: 3.732 | BLEU: 5.14
 >> Sample: <s>Last week, the ancient American Home Foreign McAT delayed a temporary cease-fire, triggering a false discussion about the country’s dramatic loss-making.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3875, lr=0.000296]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4587, lr=0.000296]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.85it/s, loss=2.4587, lr=0.000296]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.85it/s, loss=2.3979, lr=0.000295]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.85it/s, loss=2.4549, lr=0.000295]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.04it/s, loss=2.4549, lr=0.000295]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.04it/s, loss=2.3998, lr=0.000295]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.04it/s, loss=2.4551, lr=0.000294]Training:  70%|██████▉   | 273/391 [00:30<00:13,  8.99it/s, loss=2.4551, lr=0.000294]Training:  70%|██████▉   | 273/391 [00:33<00:13,  8.99it/s, loss=2.4207, lr=0.000294]Training:  70%|██████▉   | 273/391 [00:38<00:13,  8.99it/s, loss=2.4309, lr=0.000294]Training:  93%|█████████▎| 364/391 [00:40<00:02,  9.02it/s, loss=2.4309, lr=0.000294]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 58 | Time: 44s | T_Loss: 2.431 | V_Loss: 3.728 | BLEU: 5.19
 >> Sample: <s>Last week, the ancient Foreign McA stopped a temporary ceasefire, triggering a false discussion about the country’s dramatic loss-making rate of production.</s> a
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3921, lr=0.000293]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3904, lr=0.000293]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=2.3904, lr=0.000293]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=2.3728, lr=0.000293]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=2.4231, lr=0.000292]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.94it/s, loss=2.4231, lr=0.000292]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.94it/s, loss=2.4143, lr=0.000292]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.94it/s, loss=2.4170, lr=0.000292]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.90it/s, loss=2.4170, lr=0.000292]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.90it/s, loss=2.4507, lr=0.000292]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.90it/s, loss=2.4149, lr=0.000291]Training:  92%|█████████▏| 360/391 [00:40<00:03,  8.93it/s, loss=2.4149, lr=0.000291]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 59 | Time: 44s | T_Loss: 2.424 | V_Loss: 3.738 | BLEU: 5.15
 >> Sample: <s>Last week, the ancient American homebuyer Motorsi temporarily ceased, unexpectedly triggering a false discussion about the country’s dramatic yields.</s> tended to
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.4196, lr=0.000291]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4136, lr=0.000291]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.06it/s, loss=2.4136, lr=0.000291]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.06it/s, loss=2.3967, lr=0.000290]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.06it/s, loss=2.4197, lr=0.000290]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.00it/s, loss=2.4197, lr=0.000290]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.00it/s, loss=2.4596, lr=0.000290]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.00it/s, loss=2.3897, lr=0.000289]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.95it/s, loss=2.3897, lr=0.000289]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.95it/s, loss=2.4314, lr=0.000289]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.95it/s, loss=2.4578, lr=0.000289]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.96it/s, loss=2.4578, lr=0.000289]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 60 | Time: 44s | T_Loss: 2.416 | V_Loss: 3.747 | BLEU: 5.17
 >> Sample: <s>Last week, the ancient American Foreign Meeting A temporarily stopped, unexpectedly triggering a false discussion about the country’s property-rangered construction rate.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3639, lr=0.000289]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3652, lr=0.000288]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.80it/s, loss=2.3652, lr=0.000288]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.80it/s, loss=2.4017, lr=0.000288]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.80it/s, loss=2.3948, lr=0.000288]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.96it/s, loss=2.3948, lr=0.000288]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.96it/s, loss=2.4086, lr=0.000287]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.96it/s, loss=2.4846, lr=0.000287]Training:  70%|██████▉   | 272/391 [00:30<00:13,  9.02it/s, loss=2.4846, lr=0.000287]Training:  70%|██████▉   | 272/391 [00:33<00:13,  9.02it/s, loss=2.4362, lr=0.000287]Training:  70%|██████▉   | 272/391 [00:39<00:13,  9.02it/s, loss=2.4783, lr=0.000286]Training:  93%|█████████▎| 364/391 [00:40<00:02,  9.05it/s, loss=2.4783, lr=0.000286]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 61 | Time: 44s | T_Loss: 2.409 | V_Loss: 3.745 | BLEU: 5.26
 >> Sample: <s>Last week, the ancient American homebuyer Meeting delayed a temporary cease-fire, triggering fertile discussion about the country’s dramatic loss-making.</s> a
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3575, lr=0.000286]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3674, lr=0.000286]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.84it/s, loss=2.3674, lr=0.000286]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.84it/s, loss=2.3810, lr=0.000286]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.84it/s, loss=2.3758, lr=0.000285]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.98it/s, loss=2.3758, lr=0.000285]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.98it/s, loss=2.4433, lr=0.000285]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.98it/s, loss=2.4174, lr=0.000285]Training:  70%|██████▉   | 272/391 [00:30<00:13,  9.07it/s, loss=2.4174, lr=0.000285]Training:  70%|██████▉   | 272/391 [00:33<00:13,  9.07it/s, loss=2.4395, lr=0.000284]Training:  70%|██████▉   | 272/391 [00:39<00:13,  9.07it/s, loss=2.4408, lr=0.000284]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.99it/s, loss=2.4408, lr=0.000284]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 62 | Time: 44s | T_Loss: 2.402 | V_Loss: 3.741 | BLEU: 5.18
 >> Sample: <s>Last week, the ancient Family Fred McDA delayed a temporary cease-fire, unexpectedly triggering false discussion about the country’s property-caus
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3070, lr=0.000284]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.4045, lr=0.000284]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.05it/s, loss=2.4045, lr=0.000284]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.05it/s, loss=2.3293, lr=0.000283]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.05it/s, loss=2.4035, lr=0.000283]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.00it/s, loss=2.4035, lr=0.000283]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.00it/s, loss=2.4091, lr=0.000283]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.00it/s, loss=2.4404, lr=0.000282]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.92it/s, loss=2.4404, lr=0.000282]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.92it/s, loss=2.4247, lr=0.000282]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.92it/s, loss=2.4389, lr=0.000282]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.88it/s, loss=2.4389, lr=0.000282]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 63 | Time: 45s | T_Loss: 2.395 | V_Loss: 3.734 | BLEU: 5.16
 >> Sample: <s>Last week, the ancient Family Measures, a temporary ceasefire, triggered a false discussion of the country’s dramatic absorbation of home yields.</s> only
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3912, lr=0.000282]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3400, lr=0.000281]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=2.3400, lr=0.000281]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=2.3916, lr=0.000281]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=2.3962, lr=0.000281]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.99it/s, loss=2.3962, lr=0.000281]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.99it/s, loss=2.3977, lr=0.000280]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.99it/s, loss=2.4014, lr=0.000280]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.92it/s, loss=2.4014, lr=0.000280]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.92it/s, loss=2.4068, lr=0.000280]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.92it/s, loss=2.4265, lr=0.000280]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.96it/s, loss=2.4265, lr=0.000280]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 64 | Time: 45s | T_Loss: 2.389 | V_Loss: 3.734 | BLEU: 5.11
 >> Sample: <s>Last week, the ancient Family McDA stopped sloganizing, unexpectedly triggering false discussions about the country’s dramatic production-turning rate.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3294, lr=0.000279]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3561, lr=0.000279]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=2.3561, lr=0.000279]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=2.3605, lr=0.000279]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=2.3686, lr=0.000279]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.03it/s, loss=2.3686, lr=0.000279]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.03it/s, loss=2.4042, lr=0.000278]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.03it/s, loss=2.3721, lr=0.000278]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.93it/s, loss=2.3721, lr=0.000278]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.93it/s, loss=2.3570, lr=0.000278]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.93it/s, loss=2.4003, lr=0.000277]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.90it/s, loss=2.4003, lr=0.000277]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 65 | Time: 45s | T_Loss: 2.382 | V_Loss: 3.739 | BLEU: 5.12
 >> Sample: <s>Last week, the ancient American Home Family McDA stopped sweeping, unexpectedly triggering false discussions about the country’s surfacement rate of production
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3550, lr=0.000277]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3599, lr=0.000277]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.82it/s, loss=2.3599, lr=0.000277]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.82it/s, loss=2.3554, lr=0.000277]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.82it/s, loss=2.3663, lr=0.000276]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.92it/s, loss=2.3663, lr=0.000276]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.92it/s, loss=2.4035, lr=0.000276]Training:  46%|████▌     | 179/391 [00:28<00:23,  8.92it/s, loss=2.3841, lr=0.000276]Training:  69%|██████▉   | 269/391 [00:30<00:13,  8.95it/s, loss=2.3841, lr=0.000276]Training:  69%|██████▉   | 269/391 [00:33<00:13,  8.95it/s, loss=2.3610, lr=0.000276]Training:  69%|██████▉   | 269/391 [00:39<00:13,  8.95it/s, loss=2.4095, lr=0.000275]Training:  92%|█████████▏| 359/391 [00:40<00:03,  8.94it/s, loss=2.4095, lr=0.000275]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 66 | Time: 45s | T_Loss: 2.376 | V_Loss: 3.736 | BLEU: 4.86
 >> Sample: <s>Last week, the ancient American Foreign McMobacterium ceased a temporary cease-fire, triggering false discussion about the processed construction of home-country production.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3411, lr=0.000275]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3346, lr=0.000275]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.11it/s, loss=2.3346, lr=0.000275]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.11it/s, loss=2.3462, lr=0.000275]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.11it/s, loss=2.4096, lr=0.000274]Training:  47%|████▋     | 184/391 [00:20<00:23,  8.94it/s, loss=2.4096, lr=0.000274]Training:  47%|████▋     | 184/391 [00:22<00:23,  8.94it/s, loss=2.3302, lr=0.000274]Training:  47%|████▋     | 184/391 [00:28<00:23,  8.94it/s, loss=2.3635, lr=0.000274]Training:  70%|██████▉   | 273/391 [00:30<00:13,  8.89it/s, loss=2.3635, lr=0.000274]Training:  70%|██████▉   | 273/391 [00:33<00:13,  8.89it/s, loss=2.4032, lr=0.000274]Training:  70%|██████▉   | 273/391 [00:39<00:13,  8.89it/s, loss=2.3650, lr=0.000273]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.91it/s, loss=2.3650, lr=0.000273]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 67 | Time: 45s | T_Loss: 2.368 | V_Loss: 3.739 | BLEU: 5.42
 >> Sample: <s>Last week, the ancient Family Mechanism, a temporary ceasefire, triggered a false discussion about the country’s production-linked home-rate hypothesis
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3700, lr=0.000273]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3096, lr=0.000273]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.02it/s, loss=2.3096, lr=0.000273]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.02it/s, loss=2.3777, lr=0.000273]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.02it/s, loss=2.3444, lr=0.000272]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.01it/s, loss=2.3444, lr=0.000272]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.01it/s, loss=2.3620, lr=0.000272]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.01it/s, loss=2.3756, lr=0.000272]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.92it/s, loss=2.3756, lr=0.000272]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.92it/s, loss=2.4138, lr=0.000271]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.92it/s, loss=2.3835, lr=0.000271]Training:  93%|█████████▎| 363/391 [00:40<00:03,  8.97it/s, loss=2.3835, lr=0.000271]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 68 | Time: 44s | T_Loss: 2.364 | V_Loss: 3.743 | BLEU: 5.14
 >> Sample: <s>Last week, the ancient American home Mike Post was temporarily suspended, triggering false discussion about the construction of a home country’s property-s dramatic absolution rate.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3382, lr=0.000271]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3499, lr=0.000271]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.05it/s, loss=2.3499, lr=0.000271]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.05it/s, loss=2.3394, lr=0.000271]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.05it/s, loss=2.3111, lr=0.000270]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.11it/s, loss=2.3111, lr=0.000270]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.11it/s, loss=2.3120, lr=0.000270]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.11it/s, loss=2.3343, lr=0.000270]Training:  70%|███████   | 275/391 [00:30<00:12,  9.05it/s, loss=2.3343, lr=0.000270]Training:  70%|███████   | 275/391 [00:33<00:12,  9.05it/s, loss=2.3928, lr=0.000270]Training:  70%|███████   | 275/391 [00:38<00:12,  9.05it/s, loss=2.3839, lr=0.000269]Training:  93%|█████████▎| 365/391 [00:40<00:02,  9.03it/s, loss=2.3839, lr=0.000269]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 69 | Time: 44s | T_Loss: 2.357 | V_Loss: 3.747 | BLEU: 5.38
 >> Sample: <s>Last week, the ancient American homebuyer McV stopped slogan, triggering false discussion about the country’s property-rangement yields.</s> temporarily sto
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3091, lr=0.000269]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3423, lr=0.000269]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.84it/s, loss=2.3423, lr=0.000269]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.84it/s, loss=2.3295, lr=0.000269]Training:  23%|██▎       | 89/391 [00:17<00:34,  8.84it/s, loss=2.3525, lr=0.000268]Training:  46%|████▌     | 178/391 [00:20<00:24,  8.82it/s, loss=2.3525, lr=0.000268]Training:  46%|████▌     | 178/391 [00:22<00:24,  8.82it/s, loss=2.3449, lr=0.000268]Training:  46%|████▌     | 178/391 [00:28<00:24,  8.82it/s, loss=2.4325, lr=0.000268]Training:  69%|██████▉   | 271/391 [00:30<00:13,  9.02it/s, loss=2.4325, lr=0.000268]Training:  69%|██████▉   | 271/391 [00:33<00:13,  9.02it/s, loss=2.3386, lr=0.000268]Training:  69%|██████▉   | 271/391 [00:39<00:13,  9.02it/s, loss=2.3664, lr=0.000267]Training:  93%|█████████▎| 364/391 [00:40<00:02,  9.02it/s, loss=2.3664, lr=0.000267]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 70 | Time: 44s | T_Loss: 2.350 | V_Loss: 3.741 | BLEU: 5.42
 >> Sample: <s>Last week, the ancient American homebuyer McV stopped slogan, triggering a false debate about the country’s dramatic absolute loss rate.</s> made home.</s> the
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3203, lr=0.000267]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3402, lr=0.000267]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.16it/s, loss=2.3402, lr=0.000267]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.16it/s, loss=2.3396, lr=0.000267]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.16it/s, loss=2.3385, lr=0.000266]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.09it/s, loss=2.3385, lr=0.000266]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.09it/s, loss=2.3575, lr=0.000266]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.09it/s, loss=2.3613, lr=0.000266]Training:  70%|███████   | 275/391 [00:30<00:12,  8.99it/s, loss=2.3613, lr=0.000266]Training:  70%|███████   | 275/391 [00:33<00:12,  8.99it/s, loss=2.3542, lr=0.000266]Training:  70%|███████   | 275/391 [00:39<00:12,  8.99it/s, loss=2.3833, lr=0.000265]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.94it/s, loss=2.3833, lr=0.000265]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 71 | Time: 44s | T_Loss: 2.345 | V_Loss: 3.746 | BLEU: 5.46
 >> Sample: <s>Last week, the ancient American homebuyer McV stalled, an unexpected discussion of false flashion about the country’s property rate.</s> a temporary stage of ster
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3268, lr=0.000265]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2812, lr=0.000265]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=2.2812, lr=0.000265]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=2.3563, lr=0.000265]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=2.3462, lr=0.000265]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.99it/s, loss=2.3462, lr=0.000265]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.99it/s, loss=2.3797, lr=0.000264]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.99it/s, loss=2.3220, lr=0.000264]Training:  70%|███████   | 274/391 [00:30<00:12,  9.14it/s, loss=2.3220, lr=0.000264]Training:  70%|███████   | 274/391 [00:32<00:12,  9.14it/s, loss=2.3376, lr=0.000264]Training:  70%|███████   | 274/391 [00:38<00:12,  9.14it/s, loss=2.3640, lr=0.000264]Training:  94%|█████████▍| 368/391 [00:40<00:02,  9.10it/s, loss=2.3640, lr=0.000264]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 72 | Time: 44s | T_Loss: 2.341 | V_Loss: 3.747 | BLEU: 5.51
 >> Sample: <s>Last week, the ancient American homebuyer Mike was temporarily suspended, triggering a false discussion about the construction of home-productivity rates.</s> stood at a tem
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3449, lr=0.000263]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3098, lr=0.000263]Training:  24%|██▍       | 93/391 [00:10<00:32,  9.23it/s, loss=2.3098, lr=0.000263]Training:  24%|██▍       | 93/391 [00:10<00:32,  9.23it/s, loss=2.3542, lr=0.000263]Training:  24%|██▍       | 93/391 [00:16<00:32,  9.23it/s, loss=2.3047, lr=0.000263]Training:  48%|████▊     | 186/391 [00:20<00:22,  9.09it/s, loss=2.3047, lr=0.000263]Training:  48%|████▊     | 186/391 [00:22<00:22,  9.09it/s, loss=2.3347, lr=0.000262]Training:  48%|████▊     | 186/391 [00:27<00:22,  9.09it/s, loss=2.3403, lr=0.000262]Training:  71%|███████   | 278/391 [00:30<00:12,  9.12it/s, loss=2.3403, lr=0.000262]Training:  71%|███████   | 278/391 [00:33<00:12,  9.12it/s, loss=2.3224, lr=0.000262]Training:  71%|███████   | 278/391 [00:38<00:12,  9.12it/s, loss=2.3529, lr=0.000262]Training:  95%|█████████▍| 370/391 [00:40<00:02,  9.08it/s, loss=2.3529, lr=0.000262]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 73 | Time: 44s | T_Loss: 2.335 | V_Loss: 3.743 | BLEU: 5.42
 >> Sample: <s>Last week, the ancient American Family McV stopped sloganing, unexpectedly triggering false discussion about the construction of home-productivity yields.</s> st
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3124, lr=0.000262]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2860, lr=0.000261]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.13it/s, loss=2.2860, lr=0.000261]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.13it/s, loss=2.3123, lr=0.000261]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.13it/s, loss=2.3071, lr=0.000261]Training:  47%|████▋     | 184/391 [00:20<00:23,  8.97it/s, loss=2.3071, lr=0.000261]Training:  47%|████▋     | 184/391 [00:22<00:23,  8.97it/s, loss=2.3083, lr=0.000261]Training:  47%|████▋     | 184/391 [00:27<00:23,  8.97it/s, loss=2.3755, lr=0.000260]Training:  71%|███████   | 277/391 [00:30<00:12,  9.11it/s, loss=2.3755, lr=0.000260]Training:  71%|███████   | 277/391 [00:33<00:12,  9.11it/s, loss=2.3803, lr=0.000260]Training:  71%|███████   | 277/391 [00:38<00:12,  9.11it/s, loss=2.2904, lr=0.000260]Training:  95%|█████████▍| 370/391 [00:40<00:02,  9.01it/s, loss=2.2904, lr=0.000260]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 74 | Time: 44s | T_Loss: 2.329 | V_Loss: 3.755 | BLEU: 5.24
 >> Sample: <s>Last week, the ancient American homebuyer McV stopped slogan, unexpectedly triggering false discussion about the country’s home-productivity rate.</s>.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3037, lr=0.000260]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.3152, lr=0.000260]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.98it/s, loss=2.3152, lr=0.000260]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.98it/s, loss=2.2866, lr=0.000259]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.98it/s, loss=2.3476, lr=0.000259]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.01it/s, loss=2.3476, lr=0.000259]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.01it/s, loss=2.3138, lr=0.000259]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.01it/s, loss=2.3255, lr=0.000259]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.99it/s, loss=2.3255, lr=0.000259]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.99it/s, loss=2.3389, lr=0.000258]Training:  70%|██████▉   | 272/391 [00:39<00:13,  8.99it/s, loss=2.3734, lr=0.000258]Training:  93%|█████████▎| 362/391 [00:40<00:03,  8.97it/s, loss=2.3734, lr=0.000258]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 75 | Time: 44s | T_Loss: 2.324 | V_Loss: 3.740 | BLEU: 5.33
 >> Sample: <s>Last week, the ancient Family McDA stopped slogan, triggering false discussion about the home-productivity absorption rate.</s> the American home.</s> this
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2732, lr=0.000258]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2589, lr=0.000258]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.96it/s, loss=2.2589, lr=0.000258]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.96it/s, loss=2.3162, lr=0.000258]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.96it/s, loss=2.3195, lr=0.000257]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.04it/s, loss=2.3195, lr=0.000257]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.04it/s, loss=2.3537, lr=0.000257]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.04it/s, loss=2.2962, lr=0.000257]Training:  70%|██████▉   | 273/391 [00:30<00:12,  9.10it/s, loss=2.2962, lr=0.000257]Training:  70%|██████▉   | 273/391 [00:33<00:12,  9.10it/s, loss=2.2952, lr=0.000257]Training:  70%|██████▉   | 273/391 [00:38<00:12,  9.10it/s, loss=2.3373, lr=0.000257]Training:  93%|█████████▎| 365/391 [00:40<00:02,  9.02it/s, loss=2.3373, lr=0.000257]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 76 | Time: 44s | T_Loss: 2.319 | V_Loss: 3.751 | BLEU: 5.38
 >> Sample: <s>Last week, the ancient Family McMA stopped sloganizing, unexpectedly triggering false discussions about the country’s dramatic production-surrence rate.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2952, lr=0.000256]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2927, lr=0.000256]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.03it/s, loss=2.2927, lr=0.000256]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.03it/s, loss=2.3213, lr=0.000256]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.03it/s, loss=2.3116, lr=0.000256]Training:  23%|██▎       | 91/391 [00:20<00:33,  9.03it/s, loss=2.3116, lr=0.000256]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.96it/s, loss=2.3116, lr=0.000256]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.96it/s, loss=2.3021, lr=0.000256]Training:  47%|████▋     | 182/391 [00:27<00:23,  8.96it/s, loss=2.3015, lr=0.000255]Training:  70%|██████▉   | 273/391 [00:30<00:13,  8.98it/s, loss=2.3015, lr=0.000255]Training:  70%|██████▉   | 273/391 [00:33<00:13,  8.98it/s, loss=2.3703, lr=0.000255]Training:  70%|██████▉   | 273/391 [00:39<00:13,  8.98it/s, loss=2.3189, lr=0.000255]Training:  93%|█████████▎| 364/391 [00:40<00:03,  8.99it/s, loss=2.3189, lr=0.000255]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 77 | Time: 44s | T_Loss: 2.314 | V_Loss: 3.744 | BLEU: 5.40
 >> Sample: <s>Last week, the ancient American homebuyer Motorsi temporarily suspended a false discussion of the home-country production drama.</s> caused a false flag.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2397, lr=0.000255]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2928, lr=0.000254]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.12it/s, loss=2.2928, lr=0.000254]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.12it/s, loss=2.3167, lr=0.000254]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.12it/s, loss=2.2836, lr=0.000254]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.05it/s, loss=2.2836, lr=0.000254]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.05it/s, loss=2.3008, lr=0.000254]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.05it/s, loss=2.3639, lr=0.000254]Training:  70%|███████   | 275/391 [00:30<00:12,  9.03it/s, loss=2.3639, lr=0.000254]Training:  70%|███████   | 275/391 [00:33<00:12,  9.03it/s, loss=2.3267, lr=0.000253]Training:  70%|███████   | 275/391 [00:39<00:12,  9.03it/s, loss=2.3036, lr=0.000253]Training:  93%|█████████▎| 365/391 [00:40<00:02,  8.96it/s, loss=2.3036, lr=0.000253]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 78 | Time: 44s | T_Loss: 2.308 | V_Loss: 3.754 | BLEU: 5.40
 >> Sample: <s>Last week, the ancient American home Mike Post was temporarily suspended, triggering false discussions about the country’s dramatic absorbation of home yields.</s> a temporary st
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2800, lr=0.000253]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2956, lr=0.000253]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.94it/s, loss=2.2956, lr=0.000253]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.94it/s, loss=2.2897, lr=0.000253]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.94it/s, loss=2.3288, lr=0.000252]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.06it/s, loss=2.3288, lr=0.000252]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.06it/s, loss=2.2886, lr=0.000252]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.06it/s, loss=2.3199, lr=0.000252]Training:  70%|███████   | 274/391 [00:30<00:12,  9.05it/s, loss=2.3199, lr=0.000252]Training:  70%|███████   | 274/391 [00:33<00:12,  9.05it/s, loss=2.3215, lr=0.000252]Training:  70%|███████   | 274/391 [00:39<00:12,  9.05it/s, loss=2.3178, lr=0.000252]Training:  93%|█████████▎| 365/391 [00:40<00:02,  8.98it/s, loss=2.3178, lr=0.000252]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 79 | Time: 44s | T_Loss: 2.303 | V_Loss: 3.753 | BLEU: 5.19
 >> Sample: <s>Last week, the ancient American home Mike Metters stopped slogging, unexpectedly triggering false discussion about the country’s dramatic absolution rate.</s> home prices
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2852, lr=0.000251]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2548, lr=0.000251]Training:  23%|██▎       | 90/391 [00:10<00:33,  9.00it/s, loss=2.2548, lr=0.000251]Training:  23%|██▎       | 90/391 [00:11<00:33,  9.00it/s, loss=2.3240, lr=0.000251]Training:  23%|██▎       | 90/391 [00:16<00:33,  9.00it/s, loss=2.2714, lr=0.000251]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.97it/s, loss=2.2714, lr=0.000251]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.97it/s, loss=2.2889, lr=0.000251]Training:  46%|████▌     | 180/391 [00:28<00:23,  8.97it/s, loss=2.3021, lr=0.000250]Training:  69%|██████▉   | 270/391 [00:30<00:13,  8.93it/s, loss=2.3021, lr=0.000250]Training:  69%|██████▉   | 270/391 [00:33<00:13,  8.93it/s, loss=2.2831, lr=0.000250]Training:  69%|██████▉   | 270/391 [00:39<00:13,  8.93it/s, loss=2.2919, lr=0.000250]Training:  92%|█████████▏| 361/391 [00:40<00:03,  8.97it/s, loss=2.2919, lr=0.000250]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 80 | Time: 44s | T_Loss: 2.298 | V_Loss: 3.759 | BLEU: 4.92
 >> Sample: <s>Last week, the ancient Family McVA stopped sowing, triggering false discussion about the home yields.</s>ed a temporary moon.</s> about the likeli
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.3020, lr=0.000250]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2601, lr=0.000250]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.85it/s, loss=2.2601, lr=0.000250]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.85it/s, loss=2.2574, lr=0.000249]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.85it/s, loss=2.2575, lr=0.000249]Training:  46%|████▌     | 180/391 [00:20<00:23,  8.97it/s, loss=2.2575, lr=0.000249]Training:  46%|████▌     | 180/391 [00:22<00:23,  8.97it/s, loss=2.2631, lr=0.000249]Training:  46%|████▌     | 180/391 [00:27<00:23,  8.97it/s, loss=2.3234, lr=0.000249]Training:  69%|██████▉   | 271/391 [00:30<00:13,  9.01it/s, loss=2.3234, lr=0.000249]Training:  69%|██████▉   | 271/391 [00:33<00:13,  9.01it/s, loss=2.3030, lr=0.000249]Training:  69%|██████▉   | 271/391 [00:39<00:13,  9.01it/s, loss=2.3413, lr=0.000248]Training:  93%|█████████▎| 362/391 [00:40<00:03,  9.03it/s, loss=2.3413, lr=0.000248]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 81 | Time: 44s | T_Loss: 2.294 | V_Loss: 3.764 | BLEU: 5.24
 >> Sample: <s>Last week, the ancient American Home Academy stopped slogging, unexpectedly triggering false discussion about the home-productivity rate.</s> gotten
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2341, lr=0.000248]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2775, lr=0.000248]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.12it/s, loss=2.2775, lr=0.000248]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.12it/s, loss=2.3109, lr=0.000248]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.12it/s, loss=2.2482, lr=0.000248]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.02it/s, loss=2.2482, lr=0.000248]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.02it/s, loss=2.2698, lr=0.000248]Training:  47%|████▋     | 184/391 [00:28<00:22,  9.02it/s, loss=2.2858, lr=0.000247]Training:  70%|███████   | 274/391 [00:30<00:13,  8.88it/s, loss=2.2858, lr=0.000247]Training:  70%|███████   | 274/391 [00:33<00:13,  8.88it/s, loss=2.2855, lr=0.000247]Training:  70%|███████   | 274/391 [00:39<00:13,  8.88it/s, loss=2.2990, lr=0.000247]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.00it/s, loss=2.2990, lr=0.000247]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 82 | Time: 44s | T_Loss: 2.289 | V_Loss: 3.766 | BLEU: 5.14
 >> Sample: <s>Last week, the ancient American home Microbes stopped sloganing, triggering fertile discussions about the country’s home-country construction rate.</s> intervened.</s> only
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2101, lr=0.000247]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2792, lr=0.000247]Training:  23%|██▎       | 89/391 [00:10<00:33,  8.89it/s, loss=2.2792, lr=0.000247]Training:  23%|██▎       | 89/391 [00:11<00:33,  8.89it/s, loss=2.2776, lr=0.000246]Training:  23%|██▎       | 89/391 [00:16<00:33,  8.89it/s, loss=2.3270, lr=0.000246]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.00it/s, loss=2.3270, lr=0.000246]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.00it/s, loss=2.2514, lr=0.000246]Training:  46%|████▋     | 181/391 [00:28<00:23,  9.00it/s, loss=2.2736, lr=0.000246]Training:  70%|██████▉   | 272/391 [00:30<00:13,  8.95it/s, loss=2.2736, lr=0.000246]Training:  70%|██████▉   | 272/391 [00:33<00:13,  8.95it/s, loss=2.2342, lr=0.000246]Training:  70%|██████▉   | 272/391 [00:38<00:13,  8.95it/s, loss=2.3043, lr=0.000245]Training:  93%|█████████▎| 363/391 [00:40<00:03,  9.01it/s, loss=2.3043, lr=0.000245]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 83 | Time: 44s | T_Loss: 2.285 | V_Loss: 3.764 | BLEU: 5.24
 >> Sample: <s>Last week, the ancient American home Mike Post was temporarily suspended, triggering false discussion about the home-country construction rate.</s> tended to false positions.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2880, lr=0.000245]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2233, lr=0.000245]Training:  23%|██▎       | 89/391 [00:10<00:34,  8.85it/s, loss=2.2233, lr=0.000245]Training:  23%|██▎       | 89/391 [00:11<00:34,  8.85it/s, loss=2.2891, lr=0.000245]Training:  23%|██▎       | 89/391 [00:16<00:34,  8.85it/s, loss=2.2738, lr=0.000245]Training:  46%|████▌     | 179/391 [00:20<00:23,  8.89it/s, loss=2.2738, lr=0.000245]Training:  46%|████▌     | 179/391 [00:22<00:23,  8.89it/s, loss=2.2871, lr=0.000245]Training:  46%|████▌     | 179/391 [00:27<00:23,  8.89it/s, loss=2.3365, lr=0.000244]Training:  69%|██████▉   | 271/391 [00:30<00:13,  9.03it/s, loss=2.3365, lr=0.000244]Training:  69%|██████▉   | 271/391 [00:33<00:13,  9.03it/s, loss=2.2843, lr=0.000244]Training:  69%|██████▉   | 271/391 [00:38<00:13,  9.03it/s, loss=2.3443, lr=0.000244]Training:  93%|█████████▎| 363/391 [00:40<00:03,  9.07it/s, loss=2.3443, lr=0.000244]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 84 | Time: 44s | T_Loss: 2.279 | V_Loss: 3.762 | BLEU: 5.15
 >> Sample: <s>Last week, the ancient American Home Microbes stopped temporarily, triggering a false discussion about the home-country construction rate.</s> temporarily stopped slo
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2527, lr=0.000244]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2307, lr=0.000244]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.92it/s, loss=2.2307, lr=0.000244]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.92it/s, loss=2.2685, lr=0.000243]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.92it/s, loss=2.2944, lr=0.000243]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.11it/s, loss=2.2944, lr=0.000243]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.11it/s, loss=2.2730, lr=0.000243]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.11it/s, loss=2.2843, lr=0.000243]Training:  71%|███████   | 276/391 [00:30<00:12,  9.04it/s, loss=2.2843, lr=0.000243]Training:  71%|███████   | 276/391 [00:33<00:12,  9.04it/s, loss=2.3236, lr=0.000243]Training:  71%|███████   | 276/391 [00:38<00:12,  9.04it/s, loss=2.2883, lr=0.000243]Training:  94%|█████████▍| 368/391 [00:40<00:02,  9.09it/s, loss=2.2883, lr=0.000243]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 85 | Time: 44s | T_Loss: 2.275 | V_Loss: 3.761 | BLEU: 5.25
 >> Sample: <s>Last week, the garment of the ancient American Home Mike was hacked to a temporary halt, triggering false discussion about the construction of a home country’s home-count
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2592, lr=0.000242]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2531, lr=0.000242]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.19it/s, loss=2.2531, lr=0.000242]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.19it/s, loss=2.2564, lr=0.000242]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.19it/s, loss=2.2989, lr=0.000242]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.13it/s, loss=2.2989, lr=0.000242]Training:  47%|████▋     | 184/391 [00:21<00:22,  9.13it/s, loss=2.2906, lr=0.000242]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.13it/s, loss=2.2725, lr=0.000242]Training:  70%|███████   | 275/391 [00:30<00:12,  9.09it/s, loss=2.2725, lr=0.000242]Training:  70%|███████   | 275/391 [00:32<00:12,  9.09it/s, loss=2.2204, lr=0.000241]Training:  70%|███████   | 275/391 [00:38<00:12,  9.09it/s, loss=2.2677, lr=0.000241]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.07it/s, loss=2.2677, lr=0.000241]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 86 | Time: 44s | T_Loss: 2.271 | V_Loss: 3.757 | BLEU: 5.55
 >> Sample: <s>Last week, the ancient American Home Mike Posture delayed temporary cease-fire, triggering false discussions about the construction of home-country construction.</s> a temporary
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2474, lr=0.000241]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2779, lr=0.000241]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.14it/s, loss=2.2779, lr=0.000241]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.14it/s, loss=2.2705, lr=0.000241]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.14it/s, loss=2.2732, lr=0.000240]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.07it/s, loss=2.2732, lr=0.000240]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.07it/s, loss=2.2651, lr=0.000240]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.07it/s, loss=2.2599, lr=0.000240]Training:  70%|███████   | 275/391 [00:30<00:12,  9.08it/s, loss=2.2599, lr=0.000240]Training:  70%|███████   | 275/391 [00:33<00:12,  9.08it/s, loss=2.2892, lr=0.000240]Training:  70%|███████   | 275/391 [00:38<00:12,  9.08it/s, loss=2.2554, lr=0.000240]Training:  94%|█████████▍| 368/391 [00:40<00:02,  9.15it/s, loss=2.2554, lr=0.000240]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 87 | Time: 44s | T_Loss: 2.267 | V_Loss: 3.768 | BLEU: 5.37
 >> Sample: <s>Last week, the ancient American home Mike Post kept slogging, unexpectedly triggering false discussions about the country’s construction rate.</s> stood temporarily.</s> g
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2477, lr=0.000240]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2338, lr=0.000239]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.98it/s, loss=2.2338, lr=0.000239]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.98it/s, loss=2.2205, lr=0.000239]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.98it/s, loss=2.2295, lr=0.000239]Training:  46%|████▋     | 181/391 [00:20<00:23,  9.04it/s, loss=2.2295, lr=0.000239]Training:  46%|████▋     | 181/391 [00:22<00:23,  9.04it/s, loss=2.2742, lr=0.000239]Training:  46%|████▋     | 181/391 [00:27<00:23,  9.04it/s, loss=2.2925, lr=0.000239]Training:  70%|██████▉   | 272/391 [00:30<00:13,  9.03it/s, loss=2.2925, lr=0.000239]Training:  70%|██████▉   | 272/391 [00:33<00:13,  9.03it/s, loss=2.3155, lr=0.000239]Training:  70%|██████▉   | 272/391 [00:38<00:13,  9.03it/s, loss=2.2983, lr=0.000238]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.15it/s, loss=2.2983, lr=0.000238]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 88 | Time: 44s | T_Loss: 2.262 | V_Loss: 3.776 | BLEU: 5.55
 >> Sample: <s>Last week, the ancient American home Mike Post kept a temporary cease, triggering false discussion about the construction of a home country’s dramatic absolute replacement rate.</s>
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2336, lr=0.000238]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2626, lr=0.000238]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.14it/s, loss=2.2626, lr=0.000238]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.14it/s, loss=2.2322, lr=0.000238]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.14it/s, loss=2.2013, lr=0.000238]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.02it/s, loss=2.2013, lr=0.000238]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.02it/s, loss=2.2504, lr=0.000238]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.02it/s, loss=2.2760, lr=0.000237]Training:  70%|███████   | 275/391 [00:30<00:12,  9.03it/s, loss=2.2760, lr=0.000237]Training:  70%|███████   | 275/391 [00:33<00:12,  9.03it/s, loss=2.2974, lr=0.000237]Training:  70%|███████   | 275/391 [00:38<00:12,  9.03it/s, loss=2.2771, lr=0.000237]Training:  94%|█████████▍| 367/391 [00:40<00:02,  9.10it/s, loss=2.2771, lr=0.000237]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 89 | Time: 44s | T_Loss: 2.258 | V_Loss: 3.776 | BLEU: 5.28
 >> Sample: <s>Last week, the ancient Family Mechanism stopped sloganing, with surprising discussions about the false flags in home countries.</s> caused home prices.</s> to stay home.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2277, lr=0.000237]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.1949, lr=0.000237]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.00it/s, loss=2.1949, lr=0.000237]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.00it/s, loss=2.2428, lr=0.000237]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.00it/s, loss=2.2524, lr=0.000236]Training:  47%|████▋     | 182/391 [00:20<00:23,  8.97it/s, loss=2.2524, lr=0.000236]Training:  47%|████▋     | 182/391 [00:22<00:23,  8.97it/s, loss=2.2822, lr=0.000236]Training:  47%|████▋     | 182/391 [00:27<00:23,  8.97it/s, loss=2.3025, lr=0.000236]Training:  70%|███████   | 274/391 [00:30<00:12,  9.05it/s, loss=2.3025, lr=0.000236]Training:  70%|███████   | 274/391 [00:33<00:12,  9.05it/s, loss=2.2755, lr=0.000236]Training:  70%|███████   | 274/391 [00:38<00:12,  9.05it/s, loss=2.2454, lr=0.000236]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.09it/s, loss=2.2454, lr=0.000236]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 90 | Time: 44s | T_Loss: 2.255 | V_Loss: 3.778 | BLEU: 5.18
 >> Sample: <s>Last week, the ancient Family Microbessels ceased to be swept, triggering false discussions about the home-country construction rate.</s> stopped temporarily
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2389, lr=0.000236]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2621, lr=0.000235]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.01it/s, loss=2.2621, lr=0.000235]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.01it/s, loss=2.2290, lr=0.000235]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.01it/s, loss=2.2844, lr=0.000235]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.08it/s, loss=2.2844, lr=0.000235]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.08it/s, loss=2.2990, lr=0.000235]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.08it/s, loss=2.2832, lr=0.000235]Training:  70%|███████   | 275/391 [00:30<00:12,  9.07it/s, loss=2.2832, lr=0.000235]Training:  70%|███████   | 275/391 [00:33<00:12,  9.07it/s, loss=2.2376, lr=0.000235]Training:  70%|███████   | 275/391 [00:38<00:12,  9.07it/s, loss=2.2804, lr=0.000234]Training:  94%|█████████▍| 367/391 [00:40<00:02,  9.12it/s, loss=2.2804, lr=0.000234]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 91 | Time: 44s | T_Loss: 2.251 | V_Loss: 3.783 | BLEU: 5.39
 >> Sample: <s>Last week, the ancient American home Mike Post suspended a temporary halt, unexpected discussion of false flags about home yields.</s> gave rise to the wrong tone
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2495, lr=0.000234]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2248, lr=0.000234]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.04it/s, loss=2.2248, lr=0.000234]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.04it/s, loss=2.2215, lr=0.000234]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.04it/s, loss=2.2763, lr=0.000234]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.13it/s, loss=2.2763, lr=0.000234]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.13it/s, loss=2.2216, lr=0.000234]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.13it/s, loss=2.2969, lr=0.000233]Training:  70%|███████   | 275/391 [00:30<00:12,  9.11it/s, loss=2.2969, lr=0.000233]Training:  70%|███████   | 275/391 [00:33<00:12,  9.11it/s, loss=2.2158, lr=0.000233]Training:  70%|███████   | 275/391 [00:38<00:12,  9.11it/s, loss=2.2293, lr=0.000233]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.09it/s, loss=2.2293, lr=0.000233]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 92 | Time: 44s | T_Loss: 2.247 | V_Loss: 3.761 | BLEU: 5.47
 >> Sample: <s>Last week, the ancient Family Microbes denounced the temporary ceasefire, triggering false discussions about the home-country construction rate.</s> stopped tempor
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2042, lr=0.000233]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2106, lr=0.000233]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.97it/s, loss=2.2106, lr=0.000233]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.97it/s, loss=2.2523, lr=0.000233]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.97it/s, loss=2.2625, lr=0.000233]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.15it/s, loss=2.2625, lr=0.000233]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.15it/s, loss=2.2449, lr=0.000232]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.15it/s, loss=2.2231, lr=0.000232]Training:  71%|███████   | 276/391 [00:30<00:12,  9.03it/s, loss=2.2231, lr=0.000232]Training:  71%|███████   | 276/391 [00:33<00:12,  9.03it/s, loss=2.2712, lr=0.000232]Training:  71%|███████   | 276/391 [00:38<00:12,  9.03it/s, loss=2.2772, lr=0.000232]Training:  94%|█████████▍| 367/391 [00:40<00:02,  9.05it/s, loss=2.2772, lr=0.000232]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 93 | Time: 44s | T_Loss: 2.242 | V_Loss: 3.772 | BLEU: 5.46
 >> Sample: <s>Last week, the ancient American home Mike Post was temporarily suspended, triggering false discussions about the country’s home-country production processes.</s> were heard.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.2098, lr=0.000232]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2071, lr=0.000232]Training:  23%|██▎       | 91/391 [00:10<00:33,  9.04it/s, loss=2.2071, lr=0.000232]Training:  23%|██▎       | 91/391 [00:11<00:33,  9.04it/s, loss=2.2589, lr=0.000231]Training:  23%|██▎       | 91/391 [00:16<00:33,  9.04it/s, loss=2.2705, lr=0.000231]Training:  47%|████▋     | 182/391 [00:20<00:23,  9.07it/s, loss=2.2705, lr=0.000231]Training:  47%|████▋     | 182/391 [00:22<00:23,  9.07it/s, loss=2.2223, lr=0.000231]Training:  47%|████▋     | 182/391 [00:27<00:23,  9.07it/s, loss=2.2549, lr=0.000231]Training:  70%|██████▉   | 273/391 [00:30<00:13,  9.01it/s, loss=2.2549, lr=0.000231]Training:  70%|██████▉   | 273/391 [00:33<00:13,  9.01it/s, loss=2.2602, lr=0.000231]Training:  70%|██████▉   | 273/391 [00:38<00:13,  9.01it/s, loss=2.2558, lr=0.000231]Training:  93%|█████████▎| 364/391 [00:40<00:02,  9.04it/s, loss=2.2558, lr=0.000231]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 94 | Time: 44s | T_Loss: 2.239 | V_Loss: 3.779 | BLEU: 5.32
 >> Sample: <s>Last week, the ancient Family Microbesign Bureau stopped slogging, unexpectedly triggering false discussion about the home-country construction rate.</s>
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1846, lr=0.000231]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2173, lr=0.000230]Training:  24%|██▍       | 93/391 [00:10<00:32,  9.27it/s, loss=2.2173, lr=0.000230]Training:  24%|██▍       | 93/391 [00:10<00:32,  9.27it/s, loss=2.2427, lr=0.000230]Training:  24%|██▍       | 93/391 [00:16<00:32,  9.27it/s, loss=2.2695, lr=0.000230]Training:  48%|████▊     | 186/391 [00:20<00:22,  9.08it/s, loss=2.2695, lr=0.000230]Training:  48%|████▊     | 186/391 [00:22<00:22,  9.08it/s, loss=2.2166, lr=0.000230]Training:  48%|████▊     | 186/391 [00:27<00:22,  9.08it/s, loss=2.2438, lr=0.000230]Training:  71%|███████   | 276/391 [00:30<00:12,  9.03it/s, loss=2.2438, lr=0.000230]Training:  71%|███████   | 276/391 [00:33<00:12,  9.03it/s, loss=2.2533, lr=0.000230]Training:  71%|███████   | 276/391 [00:38<00:12,  9.03it/s, loss=2.2440, lr=0.000229]Training:  94%|█████████▍| 368/391 [00:40<00:02,  9.06it/s, loss=2.2440, lr=0.000229]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 95 | Time: 44s | T_Loss: 2.234 | V_Loss: 3.780 | BLEU: 5.45
 >> Sample: <s>Last week, the ancient Family Microsoon Metting, an unexpected warning of false flashioned home-equity ratios.</s> stopped this week.</s> st
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1788, lr=0.000229]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2319, lr=0.000229]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=2.2319, lr=0.000229]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=2.2307, lr=0.000229]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=2.1892, lr=0.000229]Training:  46%|████▋     | 181/391 [00:20<00:23,  8.99it/s, loss=2.1892, lr=0.000229]Training:  46%|████▋     | 181/391 [00:22<00:23,  8.99it/s, loss=2.2568, lr=0.000229]Training:  46%|████▋     | 181/391 [00:27<00:23,  8.99it/s, loss=2.2494, lr=0.000229]Training:  70%|██████▉   | 273/391 [00:30<00:13,  9.07it/s, loss=2.2494, lr=0.000229]Training:  70%|██████▉   | 273/391 [00:33<00:13,  9.07it/s, loss=2.2800, lr=0.000228]Training:  70%|██████▉   | 273/391 [00:38<00:13,  9.07it/s, loss=2.2769, lr=0.000228]Training:  93%|█████████▎| 365/391 [00:40<00:02,  8.99it/s, loss=2.2769, lr=0.000228]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 96 | Time: 44s | T_Loss: 2.230 | V_Loss: 3.772 | BLEU: 5.69
 >> Sample: <s>Last week, the ancient American homeowner Mike Post kept sloganing, triggering false discussion about the construction of home-country construction rates.</s> stood at a temporary
 >> New Best! Saving to ./transformer_checkpoints/exp_128_layer_learnable_512_8_6_2048_256_0.0005
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1837, lr=0.000228]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.2087, lr=0.000228]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.16it/s, loss=2.2087, lr=0.000228]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.16it/s, loss=2.2122, lr=0.000228]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.16it/s, loss=2.2237, lr=0.000228]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.05it/s, loss=2.2237, lr=0.000228]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.05it/s, loss=2.1817, lr=0.000227]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.05it/s, loss=2.2450, lr=0.000227]Training:  70%|███████   | 274/391 [00:30<00:12,  9.02it/s, loss=2.2450, lr=0.000227]Training:  70%|███████   | 274/391 [00:33<00:12,  9.02it/s, loss=2.2855, lr=0.000227]Training:  70%|███████   | 274/391 [00:38<00:12,  9.02it/s, loss=2.2643, lr=0.000227]Training:  94%|█████████▎| 366/391 [00:40<00:02,  9.05it/s, loss=2.2643, lr=0.000227]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 97 | Time: 44s | T_Loss: 2.227 | V_Loss: 3.786 | BLEU: 5.30
 >> Sample: <s>Last week, the ancient Family Microbial Motors stopped sowing, unexpectedly triggering false discussion about the country’s home-country construction rate.
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1947, lr=0.000227]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.1783, lr=0.000227]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.95it/s, loss=2.1783, lr=0.000227]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.95it/s, loss=2.1714, lr=0.000227]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.95it/s, loss=2.1746, lr=0.000226]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.16it/s, loss=2.1746, lr=0.000226]Training:  47%|████▋     | 184/391 [00:21<00:22,  9.16it/s, loss=2.2146, lr=0.000226]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.16it/s, loss=2.2631, lr=0.000226]Training:  71%|███████   | 278/391 [00:30<00:12,  9.18it/s, loss=2.2631, lr=0.000226]Training:  71%|███████   | 278/391 [00:32<00:12,  9.18it/s, loss=2.2530, lr=0.000226]Training:  71%|███████   | 278/391 [00:38<00:12,  9.18it/s, loss=2.2065, lr=0.000226]Training:  95%|█████████▍| 371/391 [00:40<00:02,  9.08it/s, loss=2.2065, lr=0.000226]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 98 | Time: 44s | T_Loss: 2.223 | V_Loss: 3.796 | BLEU: 5.45
 >> Sample: <s>Last week, the ancient American home Mike Post was temporarily suspended, triggering false discussion about the construction of home-equity absolute replacement rates.</s> were heard
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1886, lr=0.000226]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.1827, lr=0.000226]Training:  23%|██▎       | 90/391 [00:10<00:33,  8.99it/s, loss=2.1827, lr=0.000226]Training:  23%|██▎       | 90/391 [00:11<00:33,  8.99it/s, loss=2.2396, lr=0.000225]Training:  23%|██▎       | 90/391 [00:16<00:33,  8.99it/s, loss=2.2414, lr=0.000225]Training:  47%|████▋     | 183/391 [00:20<00:22,  9.12it/s, loss=2.2414, lr=0.000225]Training:  47%|████▋     | 183/391 [00:22<00:22,  9.12it/s, loss=2.2573, lr=0.000225]Training:  47%|████▋     | 183/391 [00:27<00:22,  9.12it/s, loss=2.1861, lr=0.000225]Training:  71%|███████   | 276/391 [00:30<00:12,  9.14it/s, loss=2.1861, lr=0.000225]Training:  71%|███████   | 276/391 [00:32<00:12,  9.14it/s, loss=2.2480, lr=0.000225]Training:  71%|███████   | 276/391 [00:38<00:12,  9.14it/s, loss=2.2431, lr=0.000225]Training:  94%|█████████▍| 368/391 [00:40<00:02,  9.05it/s, loss=2.2431, lr=0.000225]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 99 | Time: 44s | T_Loss: 2.220 | V_Loss: 3.786 | BLEU: 5.28
 >> Sample: <s>Last week, the ancient Family McMA stopped sloganing, unexpectedly triggering false discussions about the home-country construction process.</s> the United States’
Training:   0%|          | 0/391 [00:00<?, ?it/s]Training:   0%|          | 0/391 [00:00<?, ?it/s, loss=2.1596, lr=0.000225]Training:   0%|          | 0/391 [00:05<?, ?it/s, loss=2.1827, lr=0.000224]Training:  24%|██▎       | 92/391 [00:10<00:32,  9.15it/s, loss=2.1827, lr=0.000224]Training:  24%|██▎       | 92/391 [00:11<00:32,  9.15it/s, loss=2.1861, lr=0.000224]Training:  24%|██▎       | 92/391 [00:16<00:32,  9.15it/s, loss=2.2043, lr=0.000224]Training:  47%|████▋     | 184/391 [00:20<00:22,  9.11it/s, loss=2.2043, lr=0.000224]Training:  47%|████▋     | 184/391 [00:22<00:22,  9.11it/s, loss=2.2152, lr=0.000224]Training:  47%|████▋     | 184/391 [00:27<00:22,  9.11it/s, loss=2.2274, lr=0.000224]Training:  70%|███████   | 275/391 [00:30<00:12,  9.10it/s, loss=2.2274, lr=0.000224]Training:  70%|███████   | 275/391 [00:33<00:12,  9.10it/s, loss=2.2642, lr=0.000224]Training:  70%|███████   | 275/391 [00:38<00:12,  9.10it/s, loss=2.2288, lr=0.000224]Training:  94%|█████████▍| 367/391 [00:40<00:02,  9.10it/s, loss=2.2288, lr=0.000224]                                                                                     Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]                                                 Epoch 100 | Time: 44s | T_Loss: 2.216 | V_Loss: 3.776 | BLEU: 5.37
 >> Sample: <s>Last week, the ancient American home Motage stopped sloganing, unexpectedly triggering false discussion about the construction of home-country construction rates.</s> the tip of

=== Final Test Evaluation ===
Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]                                                 Test Set -> Loss: 4.3684 | BLEU: 6.25
